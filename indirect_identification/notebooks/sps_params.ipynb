{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c6e8f94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: D:\\mukul\\Desktop\\Unimelb\\Masters\\Capstone\\Learning-Dynamic-Systems\\indirect_identification\\notebooks\n",
      "Parent Directory: D:\\mukul\\Desktop\\Unimelb\\Masters\\Capstone\\Learning-Dynamic-Systems\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current notebook's directory\n",
    "parent = Path().resolve()  # Current working directory (notebook's directory)\n",
    "root = parent.parent.parent       # Go one level up\n",
    "\n",
    "print(\"Current Directory:\", parent)\n",
    "print(\"Parent Directory:\", root)\n",
    "\n",
    "# Optionally append to sys.path\n",
    "sys.path.append(str(root))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94afa117",
   "metadata": {},
   "source": [
    "# param to theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d230e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_params: 16\n",
      "A_obs:  [[ 0.  0.  0. -4.]\n",
      " [ 1.  0.  0. -3.]\n",
      " [ 0.  1.  0. -2.]\n",
      " [ 0.  0.  1. -1.]]\n",
      "B_obs: [[14 24]\n",
      " [13 23]\n",
      " [12 22]\n",
      " [11 21]]\n",
      "C_obs:  [[0 0 0 1]\n",
      " [0 1 0 0]]\n",
      "A [1 1 2 3 4]\n",
      "B [[ 0. 11. 12. 13. 14.]\n",
      " [ 0. 21. 22. 23. 24.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_states = 4\n",
    "n_inputs = 2\n",
    "n_output = 2\n",
    "noise_order = 1\n",
    "n_params = n_states + n_states*n_inputs + n_output*(noise_order+1)\n",
    "print(\"total_params:\", n_params)\n",
    "C = np.array([[0,0,0,1],[0,1,0,0]])\n",
    "def _construct_ss_from_params(params,C):\n",
    "    \"\"\"\n",
    "    Returns state space matrices A_obs,B_obs,C_obs,D_obs and the A,B polynomials\n",
    "    \"\"\"\n",
    "    # A: n_state x n_state matrix\n",
    "    A =  params[:n_states]\n",
    "    A_obs = np.hstack([np.vstack([np.zeros(n_states-1), np.eye(n_states-1)]), -np.flipud(A.reshape(A.size,-1))])\n",
    "    # B: n_state x n_input matrix\n",
    "    B = params[n_states:n_states+n_states*n_inputs].reshape(n_inputs,n_states)\n",
    "    B_obs = np.flipud(B.T)\n",
    "    # C: n_output x n_state matrix\n",
    "    C_obs = C\n",
    "    # D: n_output x n_input matrix: zero matrix for now\n",
    "    D_obs = np.zeros((n_output,n_inputs))\n",
    "\n",
    "    A = np.hstack([1, A])\n",
    "    B = np.hstack([np.zeros((n_inputs,1)), B])\n",
    "\n",
    "    return A_obs, B_obs, C_obs, D_obs, A,B\n",
    "    \n",
    "\n",
    "\n",
    "params = np.array([1,2,3,4,11,12,13,14,21,22,23,24,31,32,33,34])\n",
    "A_obs, B_obs, C_obs, D_obs, A,B = _construct_ss_from_params(params,C)\n",
    "print(\"A_obs: \", A_obs)\n",
    "print(\"B_obs:\",  B_obs)\n",
    "print(\"C_obs: \", C_obs)\n",
    "print(\"A\",A)\n",
    "print(\"B\", B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b38b63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: [31 32]\n",
      "den [1 1 2 3 4]\n",
      "num: [33 34]\n",
      "den [1 1 2 3 4]\n",
      "[[31. 32.]\n",
      " [33. 34.]]\n"
     ]
    }
   ],
   "source": [
    "C = np.empty((n_output, noise_order+1))\n",
    "if n_output == 1:\n",
    "    # if only one output, H is a scalar transfer function\n",
    "    # H = np.zeros((n_states, n_states), dtype=object)\n",
    "    j = n_states + n_states*n_inputs\n",
    "    num = params[j:j+(noise_order+1)]\n",
    "    den = A\n",
    "    C[0]=num\n",
    "    print(num, den)\n",
    "else:\n",
    "    H = np.zeros((n_output, n_output), dtype=object)\n",
    "    for i in range(n_output):\n",
    "        j = n_states + n_states*n_inputs + i*(noise_order+1)\n",
    "        # numerator and denominator of the transfer function\n",
    "        num = params[j:j+noise_order+1]\n",
    "        den = A\n",
    "        C[i]=num\n",
    "        print(\"num:\",num)\n",
    "        print(\"den\",den)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba676e59",
   "metadata": {},
   "source": [
    "# SISO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1bb034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9848867  0.44510671 0.80962354 0.04233853 0.24096281 0.30661465\n",
      " 0.06513046 0.80681941 0.91641656 0.05988858]\n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [-0.49244335  0.          0.33698732  0.          0.        ]\n",
      " [-0.22255335 -0.49244335  0.43731552  0.33698732  0.        ]\n",
      " [-0.40481177 -0.22255335  0.15442171  0.43731552  0.33698732]\n",
      " [-0.02116927 -0.40481177  0.33416984  0.15442171  0.43731552]\n",
      " [-0.12048141 -0.02116927  0.17877367  0.33416984  0.15442171]\n",
      " [-0.15330732 -0.12048141  0.30737928  0.17877367  0.33416984]\n",
      " [-0.03256523 -0.15330732  0.30158894  0.30737928  0.17877367]\n",
      " [-0.4034097  -0.03256523  0.22453096  0.30158894  0.30737928]\n",
      " [-0.45820828 -0.4034097   0.36183483  0.22453096  0.30158894]]\n",
      "(10, 5)\n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [-0.49244335  0.          0.33698732  0.          0.        ]\n",
      " [-0.22255335 -0.49244335  0.43731552  0.33698732  0.        ]\n",
      " [-0.40481177 -0.22255335  0.15442171  0.43731552  0.33698732]\n",
      " [-0.02116927 -0.40481177  0.33416984  0.15442171  0.43731552]\n",
      " [-0.12048141 -0.02116927  0.17877367  0.33416984  0.15442171]\n",
      " [-0.15330732 -0.12048141  0.30737928  0.17877367  0.33416984]\n",
      " [-0.03256523 -0.15330732  0.30158894  0.30737928  0.17877367]\n",
      " [-0.4034097  -0.03256523  0.22453096  0.30158894  0.30737928]\n",
      " [-0.45820828 -0.4034097   0.36183483  0.22453096  0.30158894]]\n",
      "(10, 5)\n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [-0.49244335  0.          0.33698732  0.          0.        ]\n",
      " [-0.22255335 -0.49244335  0.43731552  0.33698732  0.        ]\n",
      " [-0.40481177 -0.22255335  0.15442171  0.43731552  0.33698732]\n",
      " [-0.02116927 -0.40481177  0.33416984  0.15442171  0.43731552]\n",
      " [-0.12048141 -0.02116927  0.17877367  0.33416984  0.15442171]\n",
      " [-0.15330732 -0.12048141  0.30737928  0.17877367  0.33416984]\n",
      " [-0.03256523 -0.15330732  0.30158894  0.30737928  0.17877367]\n",
      " [-0.4034097  -0.03256523  0.22453096  0.30158894  0.30737928]\n",
      " [-0.45820828 -0.4034097   0.36183483  0.22453096  0.30158894]]\n",
      "True\n",
      "create_phi_optimized:    CPU:    39.315 us   +/- 10.045 (min:    30.400 / max:   170.000) us     GPU-0:    67.157 us   +/- 18.776 (min:     1.696 / max:   415.456) us\n",
      "create_phi_optimized_n:    CPU:     6.113 us   +/-  2.430 (min:     4.100 / max:    67.800) us     GPU-0:    27.286 us   +/- 16.158 (min:     0.512 / max:   497.856) us\n",
      "create_phi_optimized_n2:    CPU:     5.339 us   +/-  2.697 (min:     3.300 / max:    72.000) us     GPU-0:    29.265 us   +/- 17.219 (min:     0.448 / max:   520.576) us\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def create_phi_optimized(Y: np.ndarray, U: np.ndarray, n_a: int, n_b: int, c: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create the phi matrix optimized for the given inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    Y (array): The output sequence.\n",
    "    U (array): The input sequence.\n",
    "    n_a (int): The number of lags for the output sequence.\n",
    "    n_b (int): The number of lags for the input sequence.\n",
    "    \n",
    "    Returns:\n",
    "    array: The phi matrix.\n",
    "    \"\"\"\n",
    "    t = Y.shape[0]\n",
    "    \n",
    "    # Initialize phi with zeros\n",
    "    phi = np.zeros(shape=[t, n_a + n_b], dtype=Y.dtype)\n",
    "    \n",
    "    # Handle Y lags\n",
    "    for i in range(1, n_a + 1):\n",
    "        phi[i:, i-1] = -Y[:-i]/c\n",
    "    \n",
    "    # Handle U lags\n",
    "    for i in range(1, n_b + 1):\n",
    "        phi[i:, n_a+i-1] = U[:-i]/c\n",
    "    \n",
    "    return phi\n",
    "\n",
    "Y = np.random.rand(10)\n",
    "U = np.random.rand(10)\n",
    "print(Y)\n",
    "\n",
    "phi = create_phi_optimized(Y,U,2,3,2)\n",
    "print(phi)\n",
    "print(phi.shape)\n",
    "\n",
    "\n",
    "from numba import njit\n",
    "@njit()\n",
    "def create_phi_optimized_n(Y: np.ndarray, U: np.ndarray, n_a: int, n_b: int, c: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create the phi matrix optimized for the given inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    Y (array): The output sequence.\n",
    "    U (array): The input sequence.\n",
    "    n_a (int): The number of lags for the output sequence.\n",
    "    n_b (int): The number of lags for the input sequence.\n",
    "    \n",
    "    Returns:\n",
    "    array: The phi matrix.\n",
    "    \"\"\"\n",
    "    t = Y.shape[0]\n",
    "    \n",
    "    # Initialize phi with zeros\n",
    "    phi = np.zeros((t, n_a + n_b), dtype=Y.dtype)\n",
    "    \n",
    "    # Handle Y lags\n",
    "    for i in range(1, n_a + 1):\n",
    "        phi[i:, i-1] = -Y[:-i]/c\n",
    "    \n",
    "    # Handle U lags\n",
    "    for i in range(1, n_b + 1):\n",
    "        phi[i:, n_a+i-1] = U[:-i]/c\n",
    "    \n",
    "    return phi\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def create_phi_optimized_n2(Y: np.ndarray, U: np.ndarray, n_a: int, n_b: int, c: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create the phi matrix optimized for the given inputs using Numba-friendly loops.\n",
    "    \n",
    "    Parameters:\n",
    "    Y (array): The output sequence.\n",
    "    U (array): The input sequence.\n",
    "    n_a (int): Number of Y lags.\n",
    "    n_b (int): Number of U lags.\n",
    "    c (float): Normalization constant.\n",
    "    \n",
    "    Returns:\n",
    "    array: The phi matrix.\n",
    "    \"\"\"\n",
    "    t = Y.shape[0]\n",
    "    phi = np.zeros((t, n_a + n_b), dtype=Y.dtype)\n",
    "    # Output lags (Y)\n",
    "    for lag in range(1, n_a + 1):\n",
    "        for i in range(lag, t):\n",
    "            phi[i, lag - 1] = -Y[i - lag] / c\n",
    "    # Input lags (U)\n",
    "    for lag in range(1, n_b + 1):\n",
    "        for i in range(lag, t):\n",
    "            phi[i, n_a + lag - 1] = U[i - lag] / c\n",
    "    return phi\n",
    "phi = create_phi_optimized_n(Y,U,2,3,2)\n",
    "print(phi)\n",
    "print(phi.shape)\n",
    "\n",
    "ph2 = create_phi_optimized_n2(Y,U,2,3,2)\n",
    "print(ph2)\n",
    "print(np.all(phi==ph2))\n",
    "\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "print(benchmark(create_phi_optimized,(Y,U,2,3,2), n_repeat=1000))\n",
    "print(benchmark(create_phi_optimized_n,(Y,U,2,3,2), n_repeat=10000))\n",
    "print(benchmark(create_phi_optimized_n2,(Y,U,2,3,2), n_repeat=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc49b6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 1\n",
      "(10, 5)\n",
      "[[ 0.          0.9848867  -0.9848867  -0.4035854  -0.24146522  0.04568057\n",
      "   0.27331452 -0.12482815  0.23421172 -0.40197082]\n",
      " [ 0.          0.          0.9848867   0.44510671  0.80962354  0.04233853\n",
      "   0.24096281  0.30661465  0.06513046  0.80681941]\n",
      " [ 0.         -0.67397464 -0.87463105 -0.30884343 -0.66833968 -0.35754734\n",
      "  -0.61475856 -0.60317788 -0.44906192 -0.72366967]\n",
      " [ 0.          0.         -0.67397464 -0.87463105 -0.30884343 -0.66833968\n",
      "  -0.35754734 -0.61475856 -0.60317788 -0.44906192]\n",
      " [-0.9848867  -0.4035854  -0.24146522  0.04568057  0.27331452 -0.12482815\n",
      "   0.23421172 -0.40197082 -0.86058754  0.23329136]]\n",
      "[[ 0.          0.49244335 -0.49244335 -0.2017927  -0.12073261  0.02284028\n",
      "   0.13665726 -0.06241407  0.11710586 -0.20098541]\n",
      " [ 0.          0.          0.49244335  0.22255335  0.40481177  0.02116927\n",
      "   0.12048141  0.15330732  0.03256523  0.4034097 ]\n",
      " [ 0.         -0.33698732 -0.43731552 -0.15442171 -0.33416984 -0.17877367\n",
      "  -0.30737928 -0.30158894 -0.22453096 -0.36183483]\n",
      " [ 0.          0.         -0.67397464 -0.87463105 -0.30884343 -0.66833968\n",
      "  -0.35754734 -0.61475856 -0.60317788 -0.44906192]\n",
      " [-0.24622167 -0.10089635 -0.06036631  0.01142014  0.06832863 -0.03120704\n",
      "   0.05855293 -0.10049271 -0.21514689  0.05832284]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import lfilter\n",
    "from indirect_identification.tf_methods.fast_tfs_methods_fast_math import _convolve\n",
    "@njit()\n",
    "def create_phi_optimized_noise(Y: np.ndarray, U: np.ndarray, N: np.ndarray, n_a: int, n_b: int, n_c: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create the phi matrix optimized for the given inputs using Numba-friendly loops.\n",
    "    \n",
    "    Parameters:\n",
    "    Y (array): The output sequence.\n",
    "    U (array): The input sequence.\n",
    "    n_a (int): Number of Y lags.\n",
    "    n_b (int): Number of U lags.\n",
    "    c (float): Normalization constant.\n",
    "    \n",
    "    Returns:\n",
    "    array: The phi matrix.\n",
    "    \"\"\"\n",
    "    t = Y.shape[0]\n",
    "    n_a = n_a -1\n",
    "    n_b = n_b -1\n",
    "    n_c = n_c \n",
    "    print(n_a,n_b,n_c)\n",
    "    phi = np.zeros((t, n_a + n_b +n_c ), dtype=Y.dtype)\n",
    "    print(phi.shape)\n",
    "    # Output lags (Y)\n",
    "    for lag in range(1, n_a+1):\n",
    "        for i in range(lag, t):\n",
    "            phi[i, lag - 1] = Y[i - lag]\n",
    "    # Input lags (U)\n",
    "    for lag in range(1, n_b+1):\n",
    "        for i in range(lag, t):\n",
    "            phi[i, n_a + lag - 1] = -U[i - lag] \n",
    "    for lag in range(n_c+1):\n",
    "        for i in range(lag, t):\n",
    "            phi[i, n_a+n_b+lag]= -N[i-lag]\n",
    "    return phi.T\n",
    "# AR, X, and MA coefficients\n",
    "A = np.array([1, 0.3, -0.2])    # a1, a2\n",
    "B = np.array([0, 0.5, 0.1])     # b1, b2\n",
    "C = np.array([2])          # c1\n",
    "\n",
    "A_Y = lfilter(A,[1], Y)\n",
    "B_U = lfilter(B,[1], U)\n",
    "eps_t = A_Y - B_U\n",
    "phi = create_phi_optimized_noise(Y,U,eps_t, len(A),len(B),len(C))\n",
    "print(phi)\n",
    "\n",
    "for i in range(len(A)+len(B)-3):\n",
    "    phi[i] = lfilter([1],C, phi[i])\n",
    "\n",
    "C2 = _convolve(C,C)\n",
    "for i in range(len(C)):\n",
    "    phi[-i-1] = lfilter([1], C2, phi[-i-1])\n",
    "\n",
    "print(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cde93bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 3.3306690738754696e-16\n",
      "Median error: 2.0816681711721685e-17\n",
      "lfilter             :    CPU:    30.179 us   +/- 12.910 (min:    21.700 / max:   399.200) us     GPU-0:    54.676 us   +/- 77.492 (min:     2.208 / max:  2274.528) us\n",
      "lfilter_numba       :    CPU:    14.422 us   +/-  4.315 (min:    10.600 / max:   106.000) us     GPU-0:    27.931 us   +/- 40.417 (min:     2.208 / max:  1448.544) us\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "from cupyx.profiler import benchmark\n",
    "@njit(cache=True, fastmath=True)\n",
    "def lfilter_numba(b, a, x):\n",
    "    N = len(a)\n",
    "    M = len(b)\n",
    "    n = len(x)\n",
    "\n",
    "    if a[0] != 1.0:\n",
    "        b = b / a[0]\n",
    "        a = a / a[0]\n",
    "\n",
    "    y = np.zeros(n)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(M):\n",
    "            if i - j >= 0:\n",
    "                y[i] += b[j] * x[i - j]\n",
    "        for j in range(1, N):\n",
    "            if i - j >= 0:\n",
    "                y[i] -= a[j] * y[i - j]\n",
    "\n",
    "    return y\n",
    "\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "# Example filter coefficients\n",
    "b = np.array([0.1, 0.2, 0.3])\n",
    "a = np.array([1.0, -0.3, 0.2])\n",
    "\n",
    "# Input signal\n",
    "x = np.random.randn(1000)\n",
    "\n",
    "# Compare with scipy\n",
    "y_scipy = lfilter(b, a, x)\n",
    "y_numba = lfilter_numba(b, a, x)\n",
    "\n",
    "# Check difference\n",
    "print(\"Max error:\", np.max(np.abs(y_scipy - y_numba)))\n",
    "print(\"Median error:\",  np.median(np.abs(y_scipy - y_numba)))\n",
    "print(benchmark(lfilter,(b, a, x), n_repeat=10000))\n",
    "print(benchmark(lfilter_numba,(b, a, x), n_repeat=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "187d0a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9848867  0.44510671 0.80962354 0.04233853 0.24096281 0.30661465\n",
      " 0.06513046 0.80681941 0.91641656 0.05988858]\n",
      "[[ 0.          0.          0.          0.         -0.24622167]\n",
      " [ 0.49244335  0.         -0.33698732  0.         -0.10089635]\n",
      " [ 0.22255335  0.49244335 -0.43731552 -0.33698732 -0.06036631]\n",
      " [ 0.40481177  0.22255335 -0.15442171 -0.43731552  0.01142014]\n",
      " [ 0.02116927  0.40481177 -0.33416984 -0.15442171  0.06832863]\n",
      " [ 0.12048141  0.02116927 -0.17877367 -0.33416984 -0.03120704]\n",
      " [ 0.15330732  0.12048141 -0.30737928 -0.17877367  0.05855293]\n",
      " [ 0.03256523  0.15330732 -0.30158894 -0.30737928 -0.10049271]\n",
      " [ 0.4034097   0.03256523 -0.22453096 -0.30158894 -0.21514689]\n",
      " [ 0.45820828  0.4034097  -0.36183483 -0.22453096  0.05832284]]\n",
      "[[ 0.          0.          0.          0.         -0.24622167]\n",
      " [ 0.49244335  0.02994429 -0.33698732 -0.430415   -0.10089635]\n",
      " [ 0.22255335  0.49244335 -0.43731552 -0.33698732 -0.06036631]\n",
      " [ 0.40481177  0.22255335 -0.15442171 -0.43731552  0.01142014]\n",
      " [ 0.02116927  0.40481177 -0.33416984 -0.15442171  0.06832863]\n",
      " [ 0.12048141  0.02116927 -0.17877367 -0.33416984 -0.03120704]\n",
      " [ 0.15330732  0.12048141 -0.30737928 -0.17877367  0.05855293]\n",
      " [ 0.03256523  0.15330732 -0.30158894 -0.30737928 -0.10049271]\n",
      " [ 0.4034097   0.03256523 -0.22453096 -0.30158894 -0.21514689]\n",
      " [ 0.45820828  0.4034097  -0.36183483 -0.22453096  0.05832284]]\n",
      "create_phi_optimized_filter:    CPU:     8.452 us   +/-  6.088 (min:     5.600 / max:   749.900) us     GPU-0:    21.858 us   +/- 34.960 (min:     2.176 / max:  1286.112) us\n",
      "create_phi_optimized_filter2:    CPU:     8.683 us   +/-  5.102 (min:     5.700 / max:   354.000) us     GPU-0:    21.866 us   +/- 27.030 (min:     2.208 / max:   854.048) us\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import lfilter\n",
    "from indirect_identification.tf_methods.fast_tfs_methods_fast_math import _convolve\n",
    "from numba import prange\n",
    "@njit(cache=True, fastmath=True)\n",
    "def create_phi_optimized_filter(Y: np.ndarray, U: np.ndarray, A: np.ndarray, B: np.ndarray, C:np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create the phi matrix optimized for the given inputs using Numba-friendly loops.\n",
    "    \n",
    "    Parameters:\n",
    "    Y (array): The output sequence.\n",
    "    U (array): The input sequence.\n",
    "    n_a (int): Number of Y lags.\n",
    "    n_b (int): Number of U lags.\n",
    "    c (float): Normalization constant.\n",
    "    \n",
    "    Returns:\n",
    "    array: The phi matrix.\n",
    "    \"\"\"\n",
    "    t = Y.shape[0]\n",
    "    n_a = len(A) -1\n",
    "    n_b = len(B) -1\n",
    "    n_c = len(C) \n",
    "    num = np.array([1.0])\n",
    "    phi = np.zeros((t, n_a + n_b +n_c ), dtype=Y.dtype)\n",
    "    filtered_Y = lfilter_numba(num, C, Y)\n",
    "    filtered_U = lfilter_numba(num, C, U)\n",
    "    A_Y = lfilter_numba(A,C, filtered_Y)\n",
    "    B_U = lfilter_numba(B,C, filtered_U)\n",
    "    eps_t = A_Y - B_U\n",
    "    # Output lags (Y)\n",
    "    for lag in range(1, n_a+1):\n",
    "        for i in range(lag, t):\n",
    "            phi[i, lag - 1] = filtered_Y[i - lag]\n",
    "    # Input lags (U)\n",
    "    for lag in range(1, n_b+1):\n",
    "        for i in range(lag, t):\n",
    "            phi[i, n_a + lag - 1] = -filtered_U[i - lag] \n",
    "    for lag in range(n_c):\n",
    "        for i in range(lag, t):\n",
    "            phi[i, n_a+n_b+lag]= -eps_t[i-lag]\n",
    "    return phi\n",
    "\n",
    "@njit(cache=True,fastmath=True)\n",
    "def create_phi_optimized_filter2(Y, U, A, B, C):\n",
    "    t = Y.shape[0]\n",
    "    n_a = len(A) - 1\n",
    "    n_b = len(B) - 1\n",
    "    n_c = len(C)\n",
    "\n",
    "    idx_b = n_a\n",
    "    idx_c = n_a + n_b\n",
    "\n",
    "    phi = np.zeros((t, idx_c + n_c), dtype=np.float64)\n",
    "\n",
    "    ones = np.empty(1, dtype=np.float64)\n",
    "    ones[0] = 1.0\n",
    "\n",
    "    filtered_Y = lfilter_numba(ones, C, Y)\n",
    "    filtered_U = lfilter_numba(ones, C, U)\n",
    "    A_Y = lfilter_numba(A, C, filtered_Y)\n",
    "    B_U = lfilter_numba(B, C, filtered_U)\n",
    "    eps_t = A_Y - B_U\n",
    "\n",
    "    for i in range(t):\n",
    "        if i > 0:\n",
    "            for lag in range(1, n_a + 1):\n",
    "                    phi[i, lag - 1] = filtered_Y[i - lag]\n",
    "            for lag in range(1, n_b + 1):\n",
    "                    phi[i, idx_b + lag - 1] = -filtered_U[i - lag]\n",
    "        for lag in range(n_c):\n",
    "                phi[i, idx_c + lag] = -eps_t[i - lag]\n",
    "\n",
    "    return phi\n",
    "\n",
    "\n",
    "# AR, X, and MA coefficients\n",
    "A = np.array([1.0, 0.3, -0.2])    # a1, a2\n",
    "B = np.array([0, 0.5, 0.1])     # b1, b2\n",
    "C = np.array([2.0])          # c1\n",
    "\n",
    "\n",
    "print(Y)\n",
    "\n",
    "phi = create_phi_optimized_filter(Y,U, A, B, C)\n",
    "print(phi)\n",
    "phi = create_phi_optimized_filter2(Y,U, A, B, C)\n",
    "print(phi)\n",
    "\n",
    "\n",
    "print(benchmark(create_phi_optimized_filter,(Y,U, A, B, C), n_repeat=100000))\n",
    "print(benchmark(create_phi_optimized_filter2,(Y,U, A, B, C), n_repeat=100000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f09390",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_phi_optimized_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(benchmark(create_phi_optimized_filter2,(Y,U, A, B, C), n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m))\n",
      "File \u001b[1;32md:\\mukul\\Desktop\\Unimelb\\Masters\\Capstone\\Learning-Dynamic-Systems\\.venv\\Lib\\site-packages\\cupyx\\profiler\\_time.py:153\u001b[0m, in \u001b[0;36mbenchmark\u001b[1;34m(func, args, kwargs, n_repeat, name, n_warmup, max_duration, devices)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(devices, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`devices` should be of tuple type\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repeat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_warmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\mukul\\Desktop\\Unimelb\\Masters\\Capstone\\Learning-Dynamic-Systems\\.venv\\Lib\\site-packages\\cupyx\\profiler\\_time.py:215\u001b[0m, in \u001b[0;36m_repeat\u001b[1;34m(func, args, kwargs, n_repeat, name, n_warmup, max_duration, devices)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     runtime\u001b[38;5;241m.\u001b[39msetDevice(device)\n\u001b[1;32m--> 215\u001b[0m     \u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    217\u001b[0m     runtime\u001b[38;5;241m.\u001b[39msetDevice(prev_device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(benchmark(create_phi_optimized_filter,(Y,U, A, B, C), n_repeat=1000000))\n",
    "print(benchmark(create_phi_optimized_filter2,(Y,U, A, B, C), n_repeat=1000000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9911b9dc",
   "metadata": {},
   "source": [
    "## all perturbed phi: m x t x (n_a+n_b+n_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ffd940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  [[0.66536029 0.96895839 0.77537826]\n",
      " [0.66536029 0.96895839 0.77537826]]\n",
      "[[[ 0.          0.          0.          0.         -0.66536029]\n",
      "  [ 0.66536029  0.         -0.32683074  0.         -1.00515111]\n",
      "  [ 0.96895839  0.66536029 -0.09200026 -0.32683074 -0.85431052]]\n",
      "\n",
      " [[ 0.          0.          0.          0.         -0.66536029]\n",
      "  [ 0.66536029  0.         -0.32683074  0.         -1.00515111]\n",
      "  [ 0.96895839  0.66536029 -0.09200026 -0.32683074 -0.85431052]]]\n",
      "(2, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def create_phi_optimized_filter_multi(Y, U, A, B, C):\n",
    "    m, t = Y.shape  # m outputs, t time steps\n",
    "    n_a = len(A) - 1\n",
    "    n_b = len(B) - 1\n",
    "    n_c = len(C)\n",
    "\n",
    "    idx_b = n_a\n",
    "    idx_c = n_a + n_b\n",
    "    total_phi_len = n_a + n_b + n_c\n",
    "\n",
    "    phi = np.zeros((m, t, total_phi_len), dtype=np.float64)\n",
    "\n",
    "    ones = np.empty(1, dtype=np.float64)\n",
    "    ones[0] = 1.0\n",
    "\n",
    "    # Input filtered once (shared across outputs)\n",
    "    filtered_U = lfilter_numba(ones, C, U)\n",
    "    B_U = lfilter_numba(B, C, filtered_U)\n",
    "\n",
    "    for j in range(m):  # loop over each output dimension\n",
    "        y = Y[j]\n",
    "\n",
    "        filtered_Y = lfilter_numba(ones, C, y)\n",
    "        A_Y = lfilter_numba(A, C, filtered_Y)\n",
    "        eps_t = A_Y - B_U\n",
    "\n",
    "        for i in range(t):\n",
    "            if i > 0:\n",
    "                for lag in range(1, n_a + 1):\n",
    "                    if i - lag >= 0:\n",
    "                        phi[j, i, lag - 1] = filtered_Y[i - lag]\n",
    "                for lag in range(1, n_b + 1):\n",
    "                    if i - lag >= 0:\n",
    "                        phi[j, i, idx_b + lag - 1] = -filtered_U[i - lag]\n",
    "            for lag in range(n_c):\n",
    "                if i - lag >= 0:\n",
    "                    phi[j, i, idx_c + lag] = -eps_t[i - lag]\n",
    "\n",
    "    return phi\n",
    "\n",
    "m = 2\n",
    "t=3\n",
    "alpha = np.sign(np.random.randn(m,t))\n",
    "alpha[0, :] = 1\n",
    "Y = np.multiply(alpha, np.random.rand(t))\n",
    "U =  np.random.rand(t)\n",
    "# AR, X, and MA coefficients\n",
    "A = np.array([1.0, 0.3, -0.2])    # a1, a2\n",
    "B = np.array([0, 0.5, 0.1])     # b1, b2\n",
    "C = np.array([1.0])          # c1\n",
    "print(\"Y: \", Y)\n",
    "phi = create_phi_optimized_filter_multi(Y,U,A,B,C)\n",
    "print(phi)\n",
    "print(phi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6e184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.          0.          0.          0.        ]\n",
      "  [-0.66536029  0.          0.32683074  0.        ]\n",
      "  [-0.96895839 -0.66536029  0.09200026  0.32683074]]\n",
      "\n",
      " [[ 0.          0.          0.          0.        ]\n",
      "  [-0.66536029  0.          0.32683074  0.        ]\n",
      "  [-0.96895839 -0.66536029  0.09200026  0.32683074]]]\n",
      "create_phi_optimized_multi:    CPU:    11.406 us   +/- 36.833 (min:     2.200 / max:  3023.000) us     GPU-0:    50.704 us   +/- 178.842 (min:     2.176 / max: 10534.944) us\n"
     ]
    }
   ],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def create_phi_optimized_multi(Y: np.ndarray, U: np.ndarray, len_a: int, len_b: int, c: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create the phi matrix for perturbed output (Y: m x t) and single input (U: t).\n",
    "    \n",
    "    Parameters:\n",
    "    Y (array): Output matrix of shape (m, t).\n",
    "    U (array): Input vector of shape (t,).\n",
    "    len_a (int): len of A polynomial\n",
    "    len_b (int): len of B polynomial\n",
    "    c (float): Normalization constant.\n",
    "    \n",
    "    Returns:\n",
    "    array: Phi matrix of shape (m, t, n_a + n_b).\n",
    "    \"\"\"\n",
    "    n_a=len_a-1\n",
    "    n_b=len_b-1\n",
    "    m, t = Y.shape\n",
    "    phi = np.zeros((m, t, n_a + n_b), dtype=Y.dtype)\n",
    "\n",
    "    for j in range(m):  # for each output dimension\n",
    "        for lag in range(1, n_a + 1):\n",
    "            for i in range(lag, t):\n",
    "                phi[j, i, lag - 1] = -Y[j, i - lag] / c\n",
    "\n",
    "    for lag in range(1, n_b + 1):\n",
    "        for i in range(lag, t):\n",
    "            for j in range(m):  # input is shared across outputs\n",
    "                phi[j, i, n_a + lag - 1] = U[i - lag] / c\n",
    "\n",
    "    return phi\n",
    "\n",
    "phi = create_phi_optimized_multi(Y,U,len(A),len(B),1)\n",
    "print(phi)\n",
    "print(benchmark(create_phi_optimized_multi,(Y,U,len(A),len(B),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb96eb9",
   "metadata": {},
   "source": [
    "# MIMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eab432",
   "metadata": {},
   "source": [
    "## 2 input 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6f817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_get_p_F            :    CPU:     5.209 us   +/-  4.996 (min:     2.600 / max:   247.900) us     GPU-0:    23.020 us   +/- 56.283 (min:     2.176 / max:  2278.816) us\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "from cupyx.profiler import benchmark\n",
    "A = np.array([1.0, 0.3, -0.2, 0.1, 0.2])    # a1, a2\n",
    "B = np.array([0.0, 0.5, 0.1, 0.2, 0.1])     # b1, b2\n",
    "C = np.array([[1.0, 0.5],[1.0, 0.8]])          # c1\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def _get_p_F(A, B):\n",
    "    P = np.empty(5, dtype=np.float64)\n",
    "\n",
    "    A1, A2, A3, A4 = A[1], A[2], A[3], A[4]\n",
    "    B1, B2, B3, B4 = B[1], B[2], B[3], B[4]\n",
    "    P[0] = 0.0\n",
    "    P[1] = B3\n",
    "    P[2] = B4 + A1 * B3 - A3 * B1\n",
    "    P[3] = A1 * B4 + A2 * B3 - A3 * B2 - A4 * B1\n",
    "    P[4] = A2 * B4 - A4 * B2\n",
    "    return P\n",
    "\n",
    "\n",
    "\n",
    "print(benchmark(_get_p_F, (A,B), n_repeat=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b3fdefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 5)\n",
      "(5,)\n",
      "(2, 5, 2, 4)\n",
      "True\n",
      "create_phi_optimized_2states_1input:    CPU:     5.753 us   +/-  6.584 (min:     3.200 / max:  1316.100) us     GPU-0:    23.342 us   +/- 64.092 (min:     2.144 / max:  3934.112) us\n",
      "True\n",
      "create_phi_optimized_2states_1input2:    CPU:     5.844 us   +/-  5.243 (min:     3.000 / max:   467.900) us     GPU-0:    22.710 us   +/- 60.267 (min:     2.144 / max:  2076.672) us\n",
      "True\n",
      "create_phi_optimized_2states_1input3:    CPU:     5.551 us   +/-  4.551 (min:     3.400 / max:   472.700) us     GPU-0:    20.295 us   +/- 52.238 (min:     2.176 / max:  1883.136) us\n",
      "True\n",
      "create_phi_optimized_2states_1input4:    CPU:     5.283 us   +/-  3.162 (min:     3.100 / max:   172.200) us     GPU-0:    19.569 us   +/- 50.028 (min:     2.208 / max:  1813.440) us\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, float64\n",
    "from cupyx.profiler import benchmark\n",
    "@njit(cache=True,fastmath=True)\n",
    "def create_phi_optimized_2states_1input(Y, U, A, B, C):\n",
    "    m, n_o, t = Y.shape\n",
    "    J = np.zeros((m, t, n_o, 4))\n",
    "\n",
    "    a1, a2 = A[1], A[2]\n",
    "    b1, b2 = B[1], B[2]\n",
    "\n",
    "    for k in range(m):\n",
    "        Y1 = Y[k, 0]\n",
    "        Y2 = Y[k, 1]\n",
    "\n",
    "        for i in range(t):\n",
    "            Jk0 = J[k, i, 0]\n",
    "            Jk1 = J[k, i, 1]\n",
    "\n",
    "            if i >= 2:\n",
    "                Jk0[0] = Y1[i - 1]\n",
    "                Jk0[1] = Y1[i - 2]\n",
    "                Jk0[2] = -U[i - 1]\n",
    "                Jk0[3] = -U[i - 2]\n",
    "\n",
    "                Jk1[0] = Y2[i - 1] - b2 * U[i - 2]\n",
    "                Jk1[1] = Y2[i - 2] + b1 * U[i - 2]\n",
    "                Jk1[2] = a2 * U[i - 2]\n",
    "                Jk1[3] = -(U[i - 1] + a1 * U[i - 2])\n",
    "            elif i == 1:\n",
    "                Jk0[0] = Y1[i - 1]\n",
    "                Jk0[2] = -U[i - 1]\n",
    "\n",
    "                Jk1[0] = Y2[i - 1]\n",
    "                Jk1[3] = -U[i - 1]\n",
    "            elif i == 0:\n",
    "                pass  # J already zero\n",
    "\n",
    "    return J\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def create_phi_optimized_2states_1input2(Y, U, A, B, C):\n",
    "    m, _, t = Y.shape\n",
    "    J = np.zeros((m, t, 2, 4), dtype=np.float64)\n",
    "\n",
    "    a1: float64 = A[1]\n",
    "    a2: float64 = A[2]\n",
    "    b1: float64 = B[1]\n",
    "    b2: float64 = B[2]\n",
    "\n",
    "    for k in range(m):\n",
    "        Y1 = Y[k, 0]\n",
    "        Y2 = Y[k, 1]\n",
    "\n",
    "        # i = 1\n",
    "        if t > 1:\n",
    "            i = 1\n",
    "            im1 = i - 1\n",
    "\n",
    "            y1_im1 = Y1[im1]\n",
    "            y2_im1 = Y2[im1]\n",
    "            u_im1 = U[im1]\n",
    "\n",
    "            J[k, i, 0, 0] = y1_im1\n",
    "            J[k, i, 0, 2] = -u_im1\n",
    "            J[k, i, 1, 0] = y2_im1\n",
    "            J[k, i, 1, 3] = -u_im1\n",
    "\n",
    "        # i = 2 to t\n",
    "        for i in range(2, t):\n",
    "            im1 = i - 1\n",
    "            im2 = i - 2\n",
    "            Jk0 = J[k, i, 0]\n",
    "            Jk1 = J[k, i, 1]\n",
    "\n",
    "            y1_im1 = Y1[im1]\n",
    "            y1_im2 = Y1[im2]\n",
    "            y2_im1 = Y2[im1]\n",
    "            y2_im2 = Y2[im2]\n",
    "            u_im1 = U[im1]\n",
    "            u_im2 = U[im2]\n",
    "\n",
    "            # Row 0\n",
    "            Jk0[0] = y1_im1\n",
    "            Jk0[1] = y1_im2\n",
    "            Jk0[2] = -u_im1\n",
    "            Jk0[3] = -u_im2\n",
    "\n",
    "            # Row 1\n",
    "            Jk1[0] = y2_im1 - b2 * u_im2\n",
    "            Jk1[1] = y2_im2 + b1 * u_im2\n",
    "            Jk1[2]= a2 * u_im2\n",
    "            Jk1[3]= -(u_im1 + a1 * u_im2)\n",
    "\n",
    "    return J\n",
    "@njit(cache=True, fastmath=True)\n",
    "def create_phi_optimized_2states_1input3(Y, U, A, B, C):\n",
    "    m, _, t = Y.shape\n",
    "    \n",
    "    # Normalize U to always be (m, t)\n",
    "    if U.ndim == 1:\n",
    "        U_eff = np.broadcast_to(U, (m, U.shape[0]))\n",
    "    elif U.shape[0] == 1:\n",
    "        U_eff = np.broadcast_to(U[0], (m, U.shape[1]))\n",
    "    else:\n",
    "        U_eff = U\n",
    "\n",
    "    J = np.zeros((m, t, 2, 4))\n",
    "\n",
    "    a1 = A[1]\n",
    "    a2 = A[2]\n",
    "    b1 = B[1]\n",
    "    b2 = B[2]\n",
    "\n",
    "    for k in range(m):\n",
    "        Y1 = Y[k, 0]\n",
    "        Y2 = Y[k, 1]\n",
    "        Uk = U_eff[k]\n",
    "\n",
    "        if t > 1:\n",
    "            Jk0 = J[k, 1, 0]\n",
    "            Jk1 = J[k, 1, 1]\n",
    "\n",
    "            Jk0[0] = Y1[0]\n",
    "            Jk0[2] = -Uk[0]\n",
    "            Jk1[0] = Y2[0]\n",
    "            Jk1[3] = -Uk[0]\n",
    "\n",
    "        for i in range(2, t):\n",
    "            im1 = i - 1\n",
    "            im2 = i - 2\n",
    "\n",
    "            Jk0 = J[k, i, 0]\n",
    "            Jk1 = J[k, i, 1]\n",
    "\n",
    "            # Row 0\n",
    "            Jk0[0] = Y1[im1]\n",
    "            Jk0[1] = Y1[im2]\n",
    "            Jk0[2] = -Uk[im1]\n",
    "            Jk0[3] = -Uk[im2]\n",
    "\n",
    "            # Row 1\n",
    "            Jk1[0] = Y2[im1] - b2 * Uk[im2]\n",
    "            Jk1[1] = Y2[im2] + b1 * Uk[im2]\n",
    "            Jk1[2] = a2 * Uk[im2]\n",
    "            Jk1[3] = -(Uk[im1] + a1 * Uk[im2])\n",
    "\n",
    "    return J\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def create_phi_optimized_2states_1input4(Y, U, A, B, C):\n",
    "    m, _, t = Y.shape\n",
    "    \n",
    "    # Broadcasting U to m rows\n",
    "    if U.ndim == 1:\n",
    "        U_eff = np.broadcast_to(U, (m, U.shape[0]))\n",
    "    elif U.shape[0] == 1:\n",
    "        U_eff = np.broadcast_to(U[0], (m, U.shape[1]))\n",
    "    else:\n",
    "        U_eff = U\n",
    "    \n",
    "\n",
    "    # Preallocate J once with the correct size\n",
    "    J = np.zeros((m, t, 2, 4), dtype=np.float64)\n",
    "    \n",
    "    # Cache commonly used values from A and B\n",
    "    a1, a2 = A[1], A[2]\n",
    "    b1, b2 = B[1], B[2]\n",
    "\n",
    "    for k in range(m):\n",
    "        Y1 = Y[k, 0]\n",
    "        Y2 = Y[k, 1]\n",
    "        Uk = U_eff[k]  # This is already broadcasted to (t, )\n",
    "\n",
    "        # Handle i = 1 separately (no im2 index)\n",
    "        if t > 1:\n",
    "            Jk0 = J[k, 1, 0]\n",
    "            Jk1 = J[k, 1, 1]\n",
    "\n",
    "            Jk0[0] = Y1[0]\n",
    "            Jk0[2] = -Uk[0]\n",
    "            Jk1[0] = Y2[0]\n",
    "            Jk1[3] = -Uk[0]\n",
    "\n",
    "        # Loop for i = 2 to t\n",
    "        for i in range(2, t):\n",
    "            im1, im2 = i - 1, i - 2\n",
    "            Jk0 = J[k, i, 0]\n",
    "            Jk1 = J[k, i, 1]\n",
    "\n",
    "            # Reusing values instead of multiple calls to Y and U\n",
    "            y1_im1, y1_im2 = Y1[im1], Y1[im2]\n",
    "            y2_im1, y2_im2 = Y2[im1], Y2[im2]\n",
    "            u_im1, u_im2 = Uk[im1], Uk[im2]\n",
    "\n",
    "            # Assign values to Jk0 and Jk1 directly without intermediate variables\n",
    "            Jk0[0] = y1_im1\n",
    "            Jk0[1] = y1_im2\n",
    "            Jk0[2] = -u_im1\n",
    "            Jk0[3] = -u_im2\n",
    "\n",
    "            Jk1[0] = y2_im1 - b2 * u_im2\n",
    "            Jk1[1] = y2_im2 + b1 * u_im2\n",
    "            Jk1[2] = a2 * u_im2\n",
    "            Jk1[3] = -(u_im1 + a1 * u_im2)\n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "\n",
    "m = 2\n",
    "t=5\n",
    "n_o=2\n",
    "alpha = np.sign(np.random.randn(m,n_o,t))\n",
    "alpha[0, :] = 1\n",
    "Y = np.multiply(alpha, np.random.rand(n_o,t))\n",
    "print(Y.shape)\n",
    "U =  np.random.rand(t)\n",
    "print(U.shape)\n",
    "# AR, X, and MA coefficients\n",
    "A = np.array([1.0, 0.3, -0.2])    # a1, a2\n",
    "B = np.array([0, 0.5, 0.1])     # b1, b2\n",
    "C = np.array([1.0])          # c1\n",
    "\n",
    "phi = create_phi_optimized_2states_1input(Y,U,A,B,C)\n",
    "print(phi.shape)\n",
    "\n",
    "functions = [\n",
    "    create_phi_optimized_2states_1input,\n",
    "    create_phi_optimized_2states_1input2,\n",
    "    create_phi_optimized_2states_1input3,\n",
    "    create_phi_optimized_2states_1input4,\n",
    "]\n",
    "\n",
    "for f in functions:\n",
    "    p = f(Y,U,A,B,C)\n",
    "    print(np.allclose(phi, p))\n",
    "    print(benchmark(f, (Y, U, A, B, C), n_repeat=100000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1074463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple, List, Union\n",
    "import numpy as np\n",
    "from scipy.signal import lfilter\n",
    "from dB.sim_db import Database, SPSType\n",
    "from indirect_identification.d_tfs import d_tfs\n",
    "from types import SimpleNamespace\n",
    "from indirect_identification.sps_utils import get_phi_method\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "class SPS_indirect_model:\n",
    "    \"\"\"\n",
    "    Indirect Sign Perturbed Sum (SPS) model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, m: int, q: int, n_inputs: int, n_outputs: int, n_noise: int, N: int = 50):\n",
    "        \"\"\"\n",
    "        Initialize the SPS model.\n",
    "        assuming siso or full state obsrevation \n",
    "        Parameters:\n",
    "        m (int): The number of perturbations.\n",
    "        q (int): The number of retained perturbations.\n",
    "        N (int): The length of the perturbation sequence.\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.m = m\n",
    "        self.q = q\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        if self.n_outputs == 1:\n",
    "            self.alpha = np.random.randn(m,N)\n",
    "            self.alpha = np.sign(self.alpha)\n",
    "            self.alpha[0, :] = 1\n",
    "        else:\n",
    "            self.alpha = np.sign(np.random.randn(m,n_o,t))\n",
    "            self.alpha[0, :] = 1\n",
    "        self.pi_order = np.random.permutation(np.arange(m))\n",
    "\n",
    "        self.create_phi_optimized = get_phi_method(n_inputs, n_outputs, n_noise)\n",
    "    \n",
    "\n",
    "    def transform_to_open_loop(self, \n",
    "                               G: Union['d_tfs', Tuple[Union[List[float], np.ndarray], Union[List[float], np.ndarray]]], \n",
    "                               H: Union['d_tfs', Tuple[Union[List[float], np.ndarray], Union[List[float], np.ndarray]]], \n",
    "                               F: Union['d_tfs', Tuple[Union[List[float], np.ndarray], Union[List[float], np.ndarray]]], \n",
    "                               L: Union['d_tfs', Tuple[Union[List[float], np.ndarray], Union[List[float], np.ndarray]]]) -> Tuple['d_tfs', 'd_tfs']:\n",
    "        \"\"\"\n",
    "        Transform the closed-loop system to an open-loop system.\n",
    "        \n",
    "        Parameters:\n",
    "        G (tuple): The transfer function G.\n",
    "        H (tuple): The transfer function H.\n",
    "        F (tuple): The transfer function F.\n",
    "        L (tuple): The transfer function L.\n",
    "        \n",
    "        Returns:\n",
    "        tuple: The open-loop transfer functions G_0 and H_0.\n",
    "        \"\"\"\n",
    "        if not isinstance(G, d_tfs):\n",
    "            G = d_tfs(G)\n",
    "        if not isinstance(H, d_tfs):\n",
    "            H = d_tfs(H)\n",
    "        if not isinstance(F, d_tfs):\n",
    "            F = d_tfs(F)\n",
    "        if not isinstance(L, d_tfs):\n",
    "            L = d_tfs(L)\n",
    "\n",
    "        GF_plus_I = (G * F) + 1\n",
    "        i_GF_plus_I = 1/GF_plus_I\n",
    "        \n",
    "        if not all(tf.is_stable() for tf in [L, G, H, 1/H, i_GF_plus_I] if isinstance(tf, d_tfs)):\n",
    "            raise ValueError(f\"Error transforming to open loop: stability conditions not satisfied.\")\n",
    "        \n",
    "        G_0 = i_GF_plus_I * G * L\n",
    "        H_0 = i_GF_plus_I * H\n",
    "        return G_0, H_0\n",
    "    \n",
    "    def open_loop_sps(self, G_0, H_0, A: np.ndarray, B: np.ndarray, C: np.ndarray, Y_t: np.ndarray, U_t: np.ndarray) -> Tuple[bool, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Perform open-loop SPS.\n",
    "        \n",
    "        Parameters:\n",
    "        G_0 (d_tfs): The open-loop transfer function G_0.\n",
    "        H_0 (d_tfs): The open-loop transfer function H_0.\n",
    "        Y_t (array): The output sequence.\n",
    "        U_t (array): The input sequence.\n",
    "        n_a (int): The number of lags for the output sequence.\n",
    "        n_b (int): The number of lags for the input sequence.\n",
    "        \n",
    "        Returns:\n",
    "        tuple: A boolean indicating if the rank is within the threshold and the S values.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            Y_t = np.asarray(Y_t)\n",
    "            U_t = np.asarray(U_t)\n",
    "            YGU = Y_t - G_0*U_t\n",
    "            N_hat = (1/H_0)*YGU\n",
    "            \n",
    "            # Extract relevant segments\n",
    "            N_hat_par = N_hat[-self.N:]\n",
    "            U_t_par = U_t[-self.N-1:-1]\n",
    "            perturbed_N_hat = np.multiply(self.alpha, N_hat_par)\n",
    "            \n",
    "            # Compute y_bar vectorized\n",
    "            y_bar = G_0*U_t_par[None, :] + H_0*(perturbed_N_hat[:, None])\n",
    "            y_bar = y_bar.transpose(1, 0, 2)[0]\n",
    "            # Compute phi_tilde\n",
    "            phi_tilde = self.create_phi_optimized(y_bar, U_t_par, A, B, C)\n",
    "            # Compute Cholesky decomposition and norm squared\n",
    "            R = np.matmul(phi_tilde.transpose(0, 2, 1), phi_tilde) / len(Y_t)\n",
    "            L = np.linalg.cholesky(R)\n",
    "            Q, R = np.linalg.qr(L)\n",
    "            R_root_inv = np.linalg.solve(R, Q.transpose(0, 2, 1))\n",
    "            weighted_sum = np.matmul(phi_tilde.transpose(0, 2, 1), perturbed_N_hat[:, :, None])\n",
    "            S = np.sum(np.square(np.matmul(R_root_inv, weighted_sum)), axis=(1, 2))\n",
    "            # Ranking\n",
    "            combined = np.array(list(zip(self.pi_order, S)))\n",
    "            order = np.lexsort(combined.T)\n",
    "            rank_R = np.where(order == 0)[0][0] + 1\n",
    "            \n",
    "            return rank_R <= self.m - self.q, S\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error in open-loop SPS: {e}\")\n",
    "        \n",
    "    def open_loop_sps_mimo(self, G_0, H_0, A: np.ndarray, B: np.ndarray, C: np.ndarray, Y_t: np.ndarray, U_t: np.ndarray):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "647238e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_params: 4\n",
      "A_obs:  [[ 0.   1. ]\n",
      " [ 1.  -0.1]]\n",
      "B_obs: [[0.3]\n",
      " [0.1]]\n",
      "C_obs:  [[0 1]\n",
      " [1 0]]\n",
      "A [ 1.   0.1 -1. ]\n",
      "B [[0.  0.1 0.3]]\n",
      "[[Transfer Function: num=[0.  0.1 0.3], den=[ 1.   0.1 -1. ]]\n",
      " [Transfer Function: num=[0.   0.3  0.13], den=[ 1.   0.1 -1. ]]]\n",
      "[[Transfer Function: num=[1.], den=[ 1.   0.1 -1. ] 0]\n",
      " [0 Transfer Function: num=[1.], den=[ 1.   0.1 -1. ]]]\n",
      "[[1.]\n",
      " [1.]]\n",
      "U: (1, 100)\n",
      "Transfer Function: num=[0.  0.1 0.3], den=[ 1.   0.1 -1. ]\n",
      "[[ 0.          0.01343391  0.10435905  0.21056123  0.14539155  0.3542777\n",
      "   0.40268452  0.61392484  0.66942531  0.80926302  0.93503029  1.01742238\n",
      "   1.05506719  1.23903797  1.16364019  1.23649452  1.25812868  1.26486662\n",
      "   1.29068695  1.36531773  1.39616016  1.62085841  1.59225754  1.68169383\n",
      "   1.5552074   1.72554906  1.51482752  1.908265    1.637825    1.85671359\n",
      "   1.61322698  1.78193427  1.53469703  1.97956831  1.59571145  2.1551037\n",
      "   1.69132093  2.03853262  1.58302818  2.12936256  1.61770101  2.11930636\n",
      "   1.58140442  2.08816678  1.57605328  2.00815607  1.47631741  1.9095553\n",
      "   1.4416093   1.83320582  1.35628607  2.00374348  1.33345771  2.24323487\n",
      "   1.43651994  2.42356285  1.4506868   2.39503377  1.53174441  2.51263316\n",
      "   1.43557697  2.67361777  1.34166633  2.83607855  1.19520745  3.11072375\n",
      "   1.21187832  3.15407302  1.19789151  3.36194192  1.05972061  3.52677828\n",
      "   0.84271672  3.69155343  0.5284544   3.78013053  0.33884324  3.81980245\n",
      "   0.05637898  4.1172946  -0.14476212  4.41814732 -0.21048472  4.68649532\n",
      "  -0.56527508  5.14035848 -0.69530786  5.55558372 -0.90282893  5.96769209\n",
      "  -1.29753451  6.20586511 -1.67387159  6.70852851 -1.96885965  7.22042703\n",
      "  -2.38079675  7.63196869 -3.04124941  8.30077896]]\n",
      "(2, 100)\n",
      "calculating y_bar\n",
      "(100, 4, 2, 50) (100, 50, 4, 2)\n",
      "(100, 4, 4)\n",
      "(100, 2, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from indirect_identification.d_tfs import apply_tf_matrix, invert_matrix\n",
    "from indirect_identification.d_tfs import d_tfs\n",
    "\n",
    "\n",
    "def apply_tf_matrix2(G: np.ndarray, U: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies a matrix of transfer functions G to an input matrix U.\n",
    "\n",
    "    This function performs element-wise multiplication between each transfer function \n",
    "    in G and the corresponding row in U, then accumulates the results along the rows.\n",
    "\n",
    "    Parameters:\n",
    "        G (np.ndarray): A (m x n) matrix where each element is a transfer function \n",
    "            (or a scalar/matrix that supports multiplication with U).\n",
    "        U (np.ndarray): A (n x k) matrix representing n input signals, each of length k.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A (m x k) matrix where each row represents the output of \n",
    "        applying the corresponding transfer functions from G to the inputs in U.\n",
    "\n",
    "    Example:\n",
    "        >>> G = np.array([[tf1, tf2], [tf3, tf4]])  # Some transfer functions\n",
    "        >>> U = np.array([[u1, u2, u3], [v1, v2, v3]])  # Two input signals\n",
    "        >>> Y = apply_tf_matrix(G, U)\n",
    "        >>> print(Y.shape)  # (2, 3), output has same time length as U\n",
    "    \"\"\"\n",
    "    if U.ndim == 2:\n",
    "        # in this case we are simply applying tf to a 2d input matrix\n",
    "        m, n = G.shape  # m outputs, n inputs\n",
    "        k = U.shape[-1]  # Time length of each input sequence\n",
    "        Y = np.zeros((m, k))  # Initialize output matrix\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                Y[i, :] += (G[i, j] * U[j, :]).reshape((k,))  # Apply transfer function multiplication\n",
    "    elif U.ndim == 3 and G.shape[0]==G.shape[1]:\n",
    "        # m x n_output x t to noutput x m x t\n",
    "        # this is H, which is assumed to be all on diagonal \n",
    "        U =np.ascontiguousarray(U.transpose(1, 0, 2))\n",
    "        n,m,t = U.shape\n",
    "        Y = np.empty_like(U)\n",
    "        for i in range(n):\n",
    "            H = G[i,i]\n",
    "            for j in range(n):\n",
    "                Y[j,:] = H*U[j,:]\n",
    "        Y=Y.transpose(1,0,2)\n",
    "    return Y\n",
    "\n",
    "\n",
    "\n",
    "n_states = 2\n",
    "n_inputs = 1\n",
    "n_output = 2\n",
    "noise_order = -1\n",
    "n_params = n_states + n_states*n_inputs + n_output*(noise_order+1)\n",
    "print(\"total_params:\", n_params)\n",
    "C_obs = np.array([[0,1],[1,0]])\n",
    "\n",
    "m=100\n",
    "q=5\n",
    "t=100\n",
    "N=50\n",
    "alpha = np.sign(np.random.randn(m,n_output,N))\n",
    "alpha[0, :] = 1\n",
    "Y = np.random.rand(n_output,t)\n",
    "U =  np.random.rand(n_inputs, t)\n",
    "phi_method = get_phi_method(n_inputs=n_inputs, n_outputs=n_output, n_noise=-1)\n",
    "pi_order = np.random.permutation(np.arange(m))\n",
    "\n",
    "@njit\n",
    "def compute_phi_phiT(phi_tilde):\n",
    "    m, T, r, c = phi_tilde.shape  # (3, 5, 2, 4)\n",
    "    result = np.zeros((m, r, r))\n",
    "    for k in range(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # shape (2, 4)\n",
    "            # phi @ phi.T -> (2, 2)\n",
    "            for i in range(r):\n",
    "                for j in range(r):\n",
    "                    for l in range(c):  # inner dimension\n",
    "                        result[k, i, j] += phi[i, l] * phi[j, l]\n",
    "    result/=T\n",
    "    return result\n",
    "\n",
    "@njit\n",
    "def compute_phi_Y(phi, Y):\n",
    "    m, t, r, c = phi.shape  # (3, 5, 4, 2)\n",
    "    result = np.zeros((m, r, 1))  # (3, 4, 1)\n",
    "\n",
    "    for i in range(m):       # systems\n",
    "        for j in range(t):   # time\n",
    "            for k in range(r):     # output dim (4)\n",
    "                acc = 0.0\n",
    "                for l in range(c): # inner dim (2)\n",
    "                    acc += phi[i, j, k, l] * Y[i, l, j]  # note: Y is (m, 2, t)\n",
    "                result[i, k, 0] += acc\n",
    "    return result\n",
    "\n",
    "\n",
    "def open_loop_sps_mimo(G_0, H_0, A: np.ndarray, B: np.ndarray, C: np.ndarray, Y_t: np.ndarray, U_t: np.ndarray):\n",
    "    YGU = Y_t - apply_tf_matrix2(G_0, U_t)\n",
    "    H_invert = np.zeros_like(H_0)\n",
    "    for i in range(n_output):\n",
    "        H_invert[i,i]=d_tfs((A, C[i]))\n",
    "    N_hat = apply_tf_matrix2(H_invert,YGU)\n",
    "    print(N_hat.shape)\n",
    "    N_hat_par = N_hat[:, -N:]\n",
    "    U_t_par = U_t[:, -N-1:-1]\n",
    "    perturbed_N_hat = np.multiply(alpha, N_hat_par)\n",
    "    print(\"calculating y_bar\")\n",
    "    apply_tf_matrix2(H_0, perturbed_N_hat[:]) \n",
    "    y_bar = apply_tf_matrix2(G_0, U_t_par) + apply_tf_matrix2(H_0, perturbed_N_hat[:]) \n",
    "    phi_tilde = phi_method(y_bar, U_t_par, A, B, C)\n",
    "    print(phi_tilde.transpose(0,2, 3, 1).shape, phi_tilde.shape)\n",
    "    R = compute_phi_phiT(phi_tilde)\n",
    "    print(R.shape)\n",
    "    L = np.linalg.cholesky(R)\n",
    "    Q, R = np.linalg.qr(L)\n",
    "    R_root_inv = np.linalg.solve(R, Q.transpose(0, 2, 1))\n",
    "    print( perturbed_N_hat.shape)\n",
    "    weighted_sum = compute_phi_Y(phi_tilde, perturbed_N_hat)\n",
    "    S = np.sum(np.square(np.matmul(R_root_inv, weighted_sum)), axis=(1, 2))\n",
    "    combined = np.array(list(zip(pi_order, S)))\n",
    "    order = np.lexsort(combined.T)\n",
    "    rank_R = np.where(order == 0)[0][0] + 1\n",
    "    return rank_R <= m - q\n",
    "\n",
    "def _construct_ss_from_params(params,C_obs):\n",
    "    \"\"\"\n",
    "    Returns state space matrices A_obs,B_obs,C_obs,D_obs and the A,B polynomials\n",
    "    \"\"\"\n",
    "    # A: n_state x n_state matrix\n",
    "    A =  params[:n_states]\n",
    "    A_obs = np.hstack([np.vstack([np.zeros(n_states-1), np.eye(n_states-1)]), -np.flipud(A.reshape(A.size,-1))])\n",
    "    # B: n_state x n_input matrix\n",
    "    B = params[n_states:n_states+n_states*n_inputs].reshape(n_inputs,n_states)\n",
    "    B_obs = np.flipud(B.T)\n",
    "    # D: n_output x n_input matrix: zero matrix for now\n",
    "    D_obs = np.zeros((n_output,n_inputs))\n",
    "\n",
    "    A = np.hstack([1, A])\n",
    "    B = np.hstack([np.zeros((n_inputs,1)), B])\n",
    "\n",
    "    return A_obs, B_obs, C_obs, D_obs, A,B\n",
    "    \n",
    "\n",
    "\n",
    "params = np.array([0.1, -1.0, 0.1, 0.3])\n",
    "A_obs, B_obs, C_obs, D_obs, A,B = _construct_ss_from_params(params,C_obs)\n",
    "G = d_tfs.ss_to_tf(A_obs, B_obs, C_obs, D_obs, check_assumption=False)\n",
    "C = np.empty((n_output, 1))\n",
    "H = np.zeros((n_output, n_output), dtype=object)\n",
    "for i in range(n_output):\n",
    "    C[i]=np.array([1.0])\n",
    "    H[i,i]=d_tfs((np.array([1.0]),A))\n",
    "print(\"A_obs: \", A_obs)\n",
    "print(\"B_obs:\",  B_obs)\n",
    "print(\"C_obs: \", C_obs)\n",
    "print(\"A\",A)\n",
    "print(\"B\", B)\n",
    "print(G)\n",
    "print(H)\n",
    "print(C)\n",
    "# print(\"Y:\", Y)\n",
    "print(\"U:\", U.shape)\n",
    "print(G[0,0])\n",
    "print(G[0,0]*U)\n",
    "open_loop_sps_mimo(G, H, A, B, C, Y, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb9ee45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50)\n",
      "True\n",
      "lfilter_numba2      :    CPU:    87.372 us   +/- 25.062 (min:    64.200 / max:   621.200) us     GPU-0:   119.931 us   +/- 149.662 (min:     2.208 / max:  2459.712) us\n",
      "lfilter             :    CPU:   103.194 us   +/- 32.293 (min:    69.300 / max:   430.300) us     GPU-0:   135.600 us   +/- 125.176 (min:     2.272 / max:  1852.384) us\n",
      "lfilter_numba3      :    CPU:    87.015 us   +/- 22.453 (min:    51.800 / max:   293.300) us     GPU-0:   117.494 us   +/- 133.007 (min:     2.176 / max:  1959.200) us\n"
     ]
    }
   ],
   "source": [
    "@njit( fastmath=True)\n",
    "def lfilter_1d(b, a, x):\n",
    "    N = len(a)\n",
    "    M = len(b)\n",
    "    n = len(x)\n",
    "    y = np.zeros(n)\n",
    "\n",
    "    if a[0] != 1.0:\n",
    "        b = b / a[0]\n",
    "        a = a / a[0]\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(M):\n",
    "            if i - j >= 0:\n",
    "                y[i] += b[j] * x[i - j]\n",
    "        for j in range(1, N):\n",
    "            if i - j >= 0:\n",
    "                y[i] -= a[j] * y[i - j]\n",
    "\n",
    "    return y\n",
    "\n",
    "@njit( fastmath=True)\n",
    "def lfilter_nd(b, a, x_reshaped, n_signals, time_len):\n",
    "    y_reshaped = np.empty_like(x_reshaped)\n",
    "    for i in range(n_signals):\n",
    "        y_reshaped[i] = lfilter_1d(b, a, x_reshaped[i])\n",
    "    return y_reshaped\n",
    "\n",
    "@njit( fastmath=True)\n",
    "def lfilter_numba2(b, a, x):\n",
    "    orig_shape = x.shape\n",
    "    time_len = x.shape[-1]\n",
    "\n",
    "    # Collapse all leading dims to 1D signals\n",
    "    x_reshaped = x.reshape(-1, time_len)\n",
    "    y_reshaped = lfilter_nd(b, a, x_reshaped, x_reshaped.shape[0], time_len)\n",
    "\n",
    "    # Restore original shape\n",
    "    return y_reshaped.reshape(orig_shape)\n",
    "@njit( fastmath=True)\n",
    "def lfilter_numba3(b, a, x):\n",
    "    x = np.asarray(x)\n",
    "    shape = x.shape\n",
    "    ndim = x.ndim\n",
    "    time_len = shape[-1]\n",
    "    y = np.empty_like(x)\n",
    "\n",
    "    # Iterate over all indices except the last one (time axis)\n",
    "    it = np.ndindex(*shape[:-1])\n",
    "    for idx in it:\n",
    "        y[idx] = lfilter_1d(b, a, x[idx])\n",
    "\n",
    "    return y\n",
    "rand_input = np.random.rand(100, 50)\n",
    "print(lfilter_numba2(G[0,0].num, G[0,0].den, rand_input).shape)\n",
    "print(np.allclose(lfilter_numba2(G[0,0].num, G[0,0].den, rand_input), lfilter(G[0,0].num, G[0,0].den, rand_input)))\n",
    "print(benchmark(lfilter_numba2, (G[0,0].num, G[0,0].den, rand_input), n_repeat=10000))\n",
    "print(benchmark(lfilter, (G[0,0].num, G[0,0].den, rand_input), n_repeat=10000))\n",
    "print(benchmark(lfilter_numba3, (G[0,0].num, G[0,0].den, rand_input), n_repeat=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8ebca6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_cov_matrices:    CPU:    21.135 us   +/-  4.221 (min:    15.700 / max:    90.400) us     GPU-0:    43.044 us   +/- 73.966 (min:     2.240 / max:  1730.944) us\n",
      "True True True\n",
      "compute_cov_matrices:    CPU:    21.424 us   +/-  3.922 (min:    18.000 / max:   116.100) us     GPU-0:    44.825 us   +/- 84.464 (min:     2.208 / max:  2076.640) us\n",
      "True True True\n",
      "compute_cov_matrices_loop:    CPU:    11.647 us   +/-  5.157 (min:     7.900 / max:    99.200) us     GPU-0:    33.741 us   +/- 77.981 (min:     2.240 / max:  1822.592) us\n",
      "True True True\n",
      "compute_cov_matrices_loop1:    CPU:    11.670 us   +/-  7.900 (min:     6.100 / max:   142.700) us     GPU-0:    32.286 us   +/- 62.549 (min:     2.208 / max:  1669.632) us\n",
      "True True True\n",
      "compute_cov_matrices_loop2:    CPU:    18.082 us   +/-  4.656 (min:    13.200 / max:   105.200) us     GPU-0:    39.374 us   +/- 79.661 (min:     2.240 / max:  1868.864) us\n",
      "compute_cov_matrices_loop:    CPU:    12.033 us   +/-  6.387 (min:     8.200 / max:   383.600) us     GPU-0:    35.190 us   +/- 69.357 (min:     2.208 / max:  2660.256) us\n",
      "compute_cov_matrices_loop1:    CPU:    14.840 us   +/- 11.723 (min:     8.000 / max:  1757.700) us     GPU-0:    42.727 us   +/- 69.578 (min:     2.144 / max:  2985.408) us\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "def compute_cov_matrices_np(epsilon):\n",
    "    d, N = epsilon.shape\n",
    "\n",
    "    # Covariance matrix Lambda = 1/(N-1) * sum (eps_centered @ eps_centered.T)\n",
    "    Lambda = np.cov(epsilon)\n",
    "\n",
    "    # Second moment matrix Lambda_n = 1/N * sum (epsilon @ epsilon.T)\n",
    "    Lambda_n = epsilon @ epsilon.T / N\n",
    "\n",
    "    # Inverse of covariance\n",
    "    Lambda_inv = np.linalg.inv(Lambda)\n",
    "\n",
    "    result = Lambda_inv @ Lambda_n @ Lambda_inv\n",
    "\n",
    "    return Lambda, Lambda_n, result\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def compute_cov_matrices(epsilon):\n",
    "    d, N = epsilon.shape\n",
    "\n",
    "    # Covariance matrix Lambda = 1/(N-1) * sum (eps_centered @ eps_centered.T)\n",
    "    Lambda = np.cov(epsilon)\n",
    "\n",
    "    # Second moment matrix Lambda_n = 1/N * sum (epsilon @ epsilon.T)\n",
    "    Lambda_n = epsilon @ epsilon.T / N\n",
    "\n",
    "    # Inverse of covariance\n",
    "    Lambda_inv = np.linalg.inv(Lambda)\n",
    "\n",
    "    result = Lambda_inv @ Lambda_n @ Lambda_inv\n",
    "\n",
    "    return Lambda, Lambda_n, result\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def compute_cov_matrices_loop(epsilon):\n",
    "    d, N = epsilon.shape\n",
    "\n",
    "    # Step 1: Compute Lambda (covariance matrix)\n",
    "    # Lambda = 1 / (N-1) * epsilon_centered @ epsilon_centered.T\n",
    "\n",
    "    # First, compute mean of epsilon over N\n",
    "    mean_epsilon = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            mean_epsilon[i] += epsilon[i, n]\n",
    "        mean_epsilon[i] /= N\n",
    "\n",
    "    # Compute centered epsilon\n",
    "    epsilon_centered = np.zeros((d, N))\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            epsilon_centered[i, n] = epsilon[i, n] - mean_epsilon[i]\n",
    "\n",
    "    # Now compute epsilon_centered @ epsilon_centered.T\n",
    "    Lambda = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon_centered[i, n] * epsilon_centered[j, n]\n",
    "            Lambda[i, j] = sum_ / (N - 1)\n",
    "\n",
    "\n",
    "    # Step 2: Compute Lambda_n = 1/N * epsilon @ epsilon.T\n",
    "    Lambda_n = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon[i, n] * epsilon[j, n]\n",
    "            Lambda_n[i, j] = sum_ / N\n",
    "\n",
    "    # Step 3: Compute Lambda_inv\n",
    "    Lambda_inv = np.linalg.inv(Lambda)\n",
    "\n",
    "    # Step 4: Compute result = Lambda_inv @ Lambda_n @ Lambda_inv\n",
    "    # First compute temp = Lambda_inv @ Lambda_n\n",
    "    temp = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                temp[i, j] += Lambda_inv[i, k] * Lambda_n[k, j]\n",
    "\n",
    "    # Now compute result = temp @ Lambda_inv\n",
    "    result = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                result[i, j] += temp[i, k] * Lambda_inv[k, j]\n",
    "\n",
    "    return Lambda, Lambda_n, result\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def compute_cov_matrices_loop1(epsilon):\n",
    "    d, N = epsilon.shape\n",
    "\n",
    "    # Step 1: Compute mean of epsilon over N\n",
    "    mean_epsilon = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            mean_epsilon[i] += epsilon[i, n]\n",
    "        mean_epsilon[i] /= N\n",
    "\n",
    "    # Step 2: Centered epsilon\n",
    "    epsilon_centered = np.zeros((d, N))\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            epsilon_centered[i, n] = epsilon[i, n] - mean_epsilon[i]\n",
    "\n",
    "    # Step 3: Covariance matrix Lambda\n",
    "    Lambda = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for n in range(N):\n",
    "                Lambda[i, j] += epsilon_centered[i, n] * epsilon_centered[j, n]\n",
    "            Lambda[i, j] /= (N - 1)\n",
    "\n",
    "    # Step 4: Second moment matrix Lambda_n\n",
    "    Lambda_n = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for n in range(N):\n",
    "                Lambda_n[i, j] += epsilon[i, n] * epsilon[j, n]\n",
    "            Lambda_n[i, j] /= N\n",
    "\n",
    "    # Step 5: Inverse of Lambda\n",
    "    Lambda_inv = np.linalg.inv(Lambda)\n",
    "\n",
    "    # Step 6: Fused matrix product: result = Lambda_inv @ Lambda_n @ Lambda_inv\n",
    "    result = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                for l in range(d):\n",
    "                    result[i, j] += Lambda_inv[i, k] * Lambda_n[k, l] * Lambda_inv[l, j]\n",
    "\n",
    "    return Lambda, Lambda_n, result\n",
    "\n",
    "\n",
    "\n",
    "@njit(fastmath=True)\n",
    "def compute_cov_matrices_loop2(epsilon):\n",
    "    d, N = epsilon.shape\n",
    "\n",
    "\n",
    "    Lambda = np.cov(epsilon)\n",
    "\n",
    "    # Step 2: Compute Lambda_n = 1/N * epsilon @ epsilon.T\n",
    "    Lambda_n = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon[i, n] * epsilon[j, n]\n",
    "            Lambda_n[i, j] = sum_ / N\n",
    "\n",
    "    # Step 3: Compute Lambda_inv\n",
    "    Lambda_inv = np.linalg.inv(Lambda)\n",
    "\n",
    "    # Step 4: Compute result = Lambda_inv @ Lambda_n @ Lambda_inv\n",
    "    # First compute temp = Lambda_inv @ Lambda_n\n",
    "    temp = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                temp[i, j] += Lambda_inv[i, k] * Lambda_n[k, j]\n",
    "\n",
    "    # Now compute result = temp @ Lambda_inv\n",
    "    result = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                result[i, j] += temp[i, k] * Lambda_inv[k, j]\n",
    "\n",
    "    return Lambda, Lambda_n, result\n",
    "\n",
    "# Example: 2 variables, 50 time points\n",
    "eps = np.random.randn(2, 500)\n",
    "\n",
    "functions = [\n",
    "    compute_cov_matrices,\n",
    "    compute_cov_matrices_loop,\n",
    "    compute_cov_matrices_loop1,\n",
    "    compute_cov_matrices_loop2,\n",
    "]\n",
    "\n",
    "Lambda1, Lambda_n1, expression1 = compute_cov_matrices(eps)\n",
    "print(benchmark(compute_cov_matrices, (eps,), n_repeat=10000))\n",
    "\n",
    "for func in functions:\n",
    "    Lambda, Lambda_n, expression = func(eps)\n",
    "    print(np.allclose(Lambda, Lambda1), np.allclose(Lambda_n, Lambda_n1), np.allclose(expression, expression1))\n",
    "    print(benchmark(func, (eps,), n_repeat=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7e1c0861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_cov_matrices_loop:    CPU:    12.095 us   +/-  5.887 (min:     6.300 / max:   924.800) us     GPU-0:    34.543 us   +/- 49.193 (min:     2.176 / max:  8810.400) us\n",
      "compute_cov_matrices_loop1:    CPU:    12.281 us   +/-  6.405 (min:     7.200 / max:  1507.100) us     GPU-0:    35.381 us   +/- 47.606 (min:     0.448 / max:  6588.224) us\n"
     ]
    }
   ],
   "source": [
    "print(benchmark(compute_cov_matrices_loop, (eps,), n_repeat=1000000))\n",
    "print(benchmark(compute_cov_matrices_loop1, (eps,), n_repeat=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67b44906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the results close? True\n",
      "compute_phi_phiT_optimized:    CPU: 34609.832 us   +/- 9476.963 (min: 25543.000 / max: 80125.800) us     GPU-0: 35260.591 us   +/- 9469.024 (min: 26463.968 / max: 80820.259) us\n",
      "compute_phi_phiT_original:    CPU:  3205.467 us   +/- 403.888 (min:  2419.200 / max:  4122.200) us     GPU-0:  3860.786 us   +/- 535.423 (min:  2123.552 / max:  5407.168) us\n",
      "compute_phi_phiT_optimized_parallel:    CPU: 49060.707 us   +/- 2712.959 (min: 45527.800 / max: 58341.200) us     GPU-0: 49932.051 us   +/- 2710.107 (min: 45400.192 / max: 59201.534) us\n",
      "compute_phi_phiT_original_parallel:    CPU:  2446.931 us   +/- 556.085 (min:  1836.100 / max:  4643.000) us     GPU-0:  3234.975 us   +/- 647.831 (min:  1433.536 / max:  5420.608) us\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "from cupyx.profiler import benchmark\n",
    "# Original function (with for loops)\n",
    "@njit(cache=True, fastmath=True)\n",
    "def compute_phi_phiT_original(phi_tilde):\n",
    "    m, T, r, c = phi_tilde.shape  # (3, 5, 4, 2)\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    for k in range(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # shape (r, c)\n",
    "            # phi @ phi.T -> (r, r)\n",
    "            for i in range(r):\n",
    "                for j in range(r):\n",
    "                    for l in range(c):  # inner dimension\n",
    "                        result[k, i, j] += phi[i, l] * phi[j, l]\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "\n",
    "# Optimized function (using @)\n",
    "@njit(cache=True, fastmath=True)\n",
    "def compute_phi_phiT_optimized(phi_tilde):\n",
    "    m, T, r, c = phi_tilde.shape  # (3, 5, 4, 2)\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    for k in range(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # shape (r, c)\n",
    "            result[k] += np.dot(phi, phi.T)  # (r, c) @ (c, r) -> (r, r)\n",
    "\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "# Original function with parallelization using prange\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_phiT_original_parallel(phi_tilde):\n",
    "    m, T, r, c = phi_tilde.shape  # (3, 5, 4, 2)\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    # Parallelizing the outer loop with prange\n",
    "    for k in prange(m):  # Using prange for parallelization\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # shape (r, c)\n",
    "            # phi @ phi.T -> (r, r)\n",
    "            for i in range(r):\n",
    "                for j in range(r):\n",
    "                    for l in range(c):  # inner dimension\n",
    "                        result[k, i, j] += phi[i, l] * phi[j, l]\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "\n",
    "# Optimized function with @ and parallelization using prange\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_phiT_optimized_parallel(phi_tilde):\n",
    "    m, T, r, c = phi_tilde.shape  # (3, 5, 4, 2)\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    # Parallelizing the outer loop with prange\n",
    "    for k in prange(m):  # Using prange for parallelization\n",
    "        for t in prange(T):\n",
    "            phi = phi_tilde[k, t]  # shape (r, c)\n",
    "            phi_t = phi.T\n",
    "            result[k] += np.dot(phi, phi_t)  # (r, c) @ (c, r) -> (r, r)\n",
    "\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "# Generate random test data\n",
    "phi_tilde = np.random.randn(100, 500, 4, 2)\n",
    "\n",
    "# Compute results from both functions\n",
    "result_original = compute_phi_phiT_original(phi_tilde)\n",
    "result_optimized = compute_phi_phiT_optimized(phi_tilde)\n",
    "\n",
    "# Compare the results\n",
    "comparison = np.allclose(result_original, result_optimized)\n",
    "\n",
    "# Output the result of the comparison\n",
    "print(f\"Are the results close? {comparison}\")\n",
    "\n",
    "\n",
    "# Benchmark the optimized function\n",
    "print(benchmark(compute_phi_phiT_optimized, (phi_tilde,), n_repeat=100))\n",
    "print(benchmark(compute_phi_phiT_original, (phi_tilde,), n_repeat=100))\n",
    "print(benchmark(compute_phi_phiT_optimized_parallel, (phi_tilde,), n_repeat=100))\n",
    "print(benchmark(compute_phi_phiT_original_parallel, (phi_tilde,), n_repeat=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8881a4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_phi_lambda_phiT2:  True\n",
      "compute_phi_lambda_phiT_manual:  True\n",
      "compute_phi_lambda_phiT_flat:  True\n",
      "compute_phi_lambda_phiT_flat_all:  True\n",
      "compute_phi_lambda_phiT_numpy:  True\n",
      "compute_phi_lambda_phiT_numpy2:  True\n",
      "compute_phi_lambda_phiT:    CPU: 53725.052 us   +/- 8416.164 (min: 41550.100 / max: 75583.300) us     GPU-0: 54407.758 us   +/- 8452.618 (min: 42120.670 / max: 76380.478) us\n",
      "compute_phi_lambda_phiT2:    CPU:  4125.669 us   +/- 959.098 (min:  2165.900 / max:  7412.400) us     GPU-0:  4872.529 us   +/- 988.264 (min:  2123.072 / max:  8118.336) us\n",
      "compute_phi_lambda_phiT_manual:    CPU:  5343.521 us   +/- 935.155 (min:  3258.100 / max: 10217.300) us     GPU-0:  6109.956 us   +/- 1055.270 (min:  3651.584 / max: 10936.896) us\n",
      "compute_phi_lambda_phiT_flat:    CPU:  4685.293 us   +/- 912.687 (min:  2661.400 / max:  6155.700) us     GPU-0:  5434.447 us   +/- 979.501 (min:  3005.440 / max:  7071.360) us\n",
      "compute_phi_lambda_phiT_flat_all:    CPU:  6776.033 us   +/- 7288.636 (min:  3207.300 / max: 62973.400) us     GPU-0:  7559.038 us   +/- 7274.330 (min:  4023.360 / max: 63938.431) us\n",
      "compute_phi_lambda_phiT_numpy:    CPU: 24323.049 us   +/- 3616.449 (min: 17148.000 / max: 34498.700) us     GPU-0: 25036.896 us   +/- 3612.601 (min: 17933.344 / max: 35344.223) us\n",
      "compute_phi_lambda_phiT_numpy2:    CPU: 341155.841 us   +/- 75916.463 (min: 245067.500 / max: 673429.600) us     GPU-0: 341832.520 us   +/- 75912.171 (min: 245806.778 / max: 674173.462) us\n"
     ]
    }
   ],
   "source": [
    "from numba import njit, prange\n",
    "import numpy as np\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def compute_phi_lambda_phiT(phi_tilde, Lambda):\n",
    "    m, T, r, c = phi_tilde.shape  # (m, T, r, c)\n",
    "    result = np.zeros((m, r, r))\n",
    "    for k in range(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # shape (r, c)\n",
    "            result[k] += phi @ Lambda @ phi.T  # (r, c) @ (c, r) -> (r, r)\n",
    "    result /= T\n",
    "    return result\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_lambda_phiT_manual(phi_tilde, Lambda):\n",
    "    m, T, r, c = phi_tilde.shape  # (m, T, r, c)\n",
    "    result = np.zeros((m, r, r))\n",
    "\n",
    "    for k in prange(m):\n",
    "        for t in range(T):\n",
    "            for i in range(r):         # row of phi\n",
    "                phi_k_t_i = phi_tilde[k, t, i]  # shape (c,)\n",
    "                for j in range(r):     # row of phi.T (col of phi)\n",
    "                    val = 0.0\n",
    "                    phi_k_t_j = phi_tilde[k, t, j]  # shape (c,)\n",
    "                    for l in range(c):     # col of phi, row of Lambda\n",
    "                        phi_tilde_k_t_i_l = phi_k_t_i[l]  # shape (c,)\n",
    "                        for q in range(c): # col of Lambda\n",
    "                            val += phi_tilde_k_t_i_l * Lambda[l, q] * phi_k_t_j[q]\n",
    "                    result[k, i, j] += val\n",
    "\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_lambda_phiT2(phi_tilde, Lambda):\n",
    "    m, T, r, c = phi_tilde.shape  # (m, T, r, c)\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    for k in prange(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # (r, c)\n",
    "\n",
    "            for i in range(r):\n",
    "                for j in range(r):\n",
    "                    sum_ = 0.0\n",
    "                    for l in range(c):\n",
    "                        for p in range(c):\n",
    "                            sum_ += phi[i, l] * Lambda[l, p] * phi[j, p]\n",
    "                    result[k, i, j] += sum_\n",
    "\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_lambda_phiT_flat(phi_tilde, Lambda):\n",
    "    m, T, r, c = phi_tilde.shape\n",
    "    result = np.zeros((m, r, r))\n",
    "\n",
    "    # Total number of iterations for (k, t)\n",
    "    total = m * T\n",
    "\n",
    "    for idx in prange(total):\n",
    "        k = idx // T\n",
    "        t = idx % T\n",
    "\n",
    "        for i in range(r):\n",
    "            phi_k_t_i = phi_tilde[k, t, i]\n",
    "            for j in range(r):\n",
    "                phi_k_t_j = phi_tilde[k, t, j]\n",
    "                val = 0.0\n",
    "                for l in range(c):\n",
    "                    phi_il = phi_k_t_i[l]\n",
    "                    for q in range(c):\n",
    "                        val += phi_il * Lambda[l, q] * phi_k_t_j[q]\n",
    "                result[k, i, j] += val\n",
    "\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_lambda_phiT_flat_all(phi_tilde, Lambda):\n",
    "    m, T, r, c = phi_tilde.shape\n",
    "    result = np.zeros((m, r, r))\n",
    "\n",
    "    total = m * T * r\n",
    "\n",
    "    for index in prange(total):\n",
    "        k = index // (T * r)\n",
    "        t = (index % (T * r)) // r\n",
    "        i = index % r\n",
    "\n",
    "        phi_k_t_i = phi_tilde[k, t, i]\n",
    "        for j in range(r):\n",
    "            phi_k_t_j = phi_tilde[k, t, j]\n",
    "            val = 0.0\n",
    "            for l in range(c):\n",
    "                phi_il = phi_k_t_i[l]\n",
    "                for q in range(c):\n",
    "                    val += phi_il * Lambda[l, q] * phi_k_t_j[q]\n",
    "            result[k, i, j] += val\n",
    "\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "def compute_phi_lambda_phiT_numpy(phi_tilde, Lambda):\n",
    "    # phi_tilde: (m, T, r, c)\n",
    "    # Lambda: (c, c)\n",
    "    phi_lambda = phi_tilde @ Lambda               # (m, T, r, c) @ (c, c) -> (m, T, r, c)\n",
    "    result = np.matmul(phi_lambda, phi_tilde.transpose(0, 1, 3, 2))  # (m, T, r, r)\n",
    "    result = result.mean(axis=1)                  # average over T\n",
    "    return result\n",
    "\n",
    "def compute_phi_lambda_phiT_numpy2(phi_tilde, Lambda):\n",
    "    m, T, r, c = phi_tilde.shape  # (m, T, r, c)\n",
    "    result = np.zeros((m, r, r))\n",
    "    for k in range(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # shape (r, c)\n",
    "            result[k] += phi @ Lambda @ phi.T  # (r, c) @ (c, r) -> (r, r)\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "# Generate random test data\n",
    "phi_tilde = np.random.randn(100, 500, 4, 2)\n",
    "# Lambda matrix\n",
    "eps = np.random.randn(2, 500)\n",
    "Lambda, Lambda_n= compute_cov_matrices(eps)\n",
    "\n",
    "functions = [\n",
    "    compute_phi_lambda_phiT,\n",
    "    compute_phi_lambda_phiT2,\n",
    "    compute_phi_lambda_phiT_manual,\n",
    "    compute_phi_lambda_phiT_flat,\n",
    "    compute_phi_lambda_phiT_flat_all,\n",
    "    compute_phi_lambda_phiT_numpy,\n",
    "    compute_phi_lambda_phiT_numpy2\n",
    "]\n",
    "\n",
    "plp1 = compute_phi_lambda_phiT(phi_tilde, Lambda)\n",
    "\n",
    "for func in functions:\n",
    "    if func != compute_phi_lambda_phiT:\n",
    "        plp = func(phi_tilde, Lambda)\n",
    "        print(f\"{func.__name__}: \", np.allclose(plp1, plp))\n",
    "\n",
    "# Benchmark the optimized function\n",
    "for func in functions:\n",
    "    print(benchmark(func, (phi_tilde, Lambda), n_repeat=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7f33035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random test data\n",
    "phi_tilde = np.random.randn(100, 500, 4, 2)\n",
    "# Lambda matrix\n",
    "eps = np.random.randn(2, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "222d5106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4, 4)\n",
      "compute_R_np        :    CPU: 19912.876 us   +/- 4974.924 (min: 14720.100 / max: 44286.300) us     GPU-0: 20449.287 us   +/- 5085.501 (min: 15223.328 / max: 44843.006) us\n",
      "compute_R:  True\n",
      "compute_R           :    CPU:  8838.961 us   +/- 1596.744 (min:  5874.200 / max: 12011.600) us     GPU-0:  9606.922 us   +/- 1583.851 (min:  6603.808 / max: 12771.232) us\n",
      "compute_R2:  True\n",
      "compute_R2          :    CPU:  9043.895 us   +/- 2384.871 (min:  5683.100 / max: 19738.700) us     GPU-0:  9757.777 us   +/- 2396.750 (min:  6224.000 / max: 19707.968) us\n"
     ]
    }
   ],
   "source": [
    "@njit(fastmath=True)\n",
    "def compute_cov_matrices(epsilon):\n",
    "    d, N = epsilon.shape\n",
    "\n",
    "    # Step 1: Compute Lambda (covariance matrix)\n",
    "    # Lambda = 1 / (N-1) * epsilon_centered @ epsilon_centered.T\n",
    "\n",
    "    # First, compute mean of epsilon over N\n",
    "    mean_epsilon = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            mean_epsilon[i] += epsilon[i, n]\n",
    "        mean_epsilon[i] /= N\n",
    "\n",
    "    # Compute centered epsilon\n",
    "    epsilon_centered = np.zeros((d, N))\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            epsilon_centered[i, n] = epsilon[i, n] - mean_epsilon[i]\n",
    "\n",
    "    # Now compute epsilon_centered @ epsilon_centered.T\n",
    "    Lambda = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon_centered[i, n] * epsilon_centered[j, n]\n",
    "            Lambda[i, j] = sum_ / (N - 1)\n",
    "\n",
    "\n",
    "    # Step 2: Compute Lambda_n = 1/N * epsilon @ epsilon.T\n",
    "    Lambda_n = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon[i, n] * epsilon[j, n]\n",
    "            Lambda_n[i, j] = sum_ / N\n",
    "\n",
    "    # Step 3: Compute Lambda_inv\n",
    "    Lambda_inv = np.linalg.inv(Lambda)\n",
    "\n",
    "    # Step 4: Compute result = Lambda_inv @ Lambda_n @ Lambda_inv\n",
    "    # First compute temp = Lambda_inv @ Lambda_n\n",
    "    temp = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                temp[i, j] += Lambda_inv[i, k] * Lambda_n[k, j]\n",
    "\n",
    "    # Now compute result = temp @ Lambda_inv\n",
    "    result = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                result[i, j] += temp[i, k] * Lambda_inv[k, j]\n",
    "\n",
    "    return Lambda_inv, result\n",
    "\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_R(epsilon, phi_tilde):\n",
    "    \"\"\"\n",
    "    Computes the R matrix using the covariance matrices and phi_tilde.\n",
    "    R = sqrt(Delat(lambda^{-1})^{-1} @ Delta(lambda^{-1}lambda_n lambda^{-1}) @ Delta(lambda^{-1})^{-1})\n",
    "    \"\"\"\n",
    "    Lambda_inv, Lambda_inv_n = compute_cov_matrices(epsilon)\n",
    "    Delta_lambda = compute_phi_lambda_phiT_manual(phi_tilde, Lambda_inv)\n",
    "    Delta_lambda_n = compute_phi_lambda_phiT_manual(phi_tilde, Lambda_inv_n)\n",
    "\n",
    "    m, r, _ = Delta_lambda.shape\n",
    "\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    for i in prange(m):\n",
    "        Delta_inv = np.linalg.inv(Delta_lambda[i])\n",
    "        temp = np.dot(Delta_inv, Delta_lambda_n[i])\n",
    "        R = np.dot(temp, Delta_inv)\n",
    "        result[i] = np.linalg.cholesky(R)\n",
    "\n",
    "    return result\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_R2(epsilon, phi_tilde):\n",
    "    \"\"\"\n",
    "    Computes the R matrix using the covariance matrices and phi_tilde.\n",
    "    R = sqrt(Delta(lambda^{-1})^{-1} @ Delta(lambda^{-1} lambda_n lambda^{-1}) @ Delta(lambda^{-1})^{-1})\n",
    "    \"\"\"\n",
    "    Lambda_inv, Lambda_inv_n = compute_cov_matrices(epsilon)\n",
    "    Delta_lambda = compute_phi_lambda_phiT_manual(phi_tilde, Lambda_inv)\n",
    "    Delta_lambda_n = compute_phi_lambda_phiT_manual(phi_tilde, Lambda_inv_n)\n",
    "\n",
    "    m, r, _ = Delta_lambda.shape\n",
    "\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    for i in prange(m):\n",
    "        Delta_inv = np.linalg.inv(Delta_lambda[i])\n",
    "\n",
    "        # Compute R = Delta_inv @ Delta_lambda_n[i] @ Delta_inv manually\n",
    "        R = np.zeros((r, r))\n",
    "        for j in range(r):\n",
    "            for k in range(r):\n",
    "                sum_ = 0.0\n",
    "                for l in range(r):\n",
    "                    Delta_inv_jl = Delta_inv[j, l]\n",
    "                    Delta_lambda_n_il = Delta_lambda_n[i, l]\n",
    "                    for p in range(r):\n",
    "                        sum_ += Delta_inv_jl *  Delta_lambda_n_il[p] * Delta_inv[p, k]\n",
    "                R[j, k] = sum_\n",
    "\n",
    "        # Now compute the Cholesky decomposition\n",
    "        result[i] = np.linalg.cholesky(R)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_R_np(epsilon, phi_tilde):\n",
    "    Lambda_inv, Lambda_inv_n = compute_cov_matrices(epsilon)\n",
    "    Delta_lambda = compute_phi_lambda_phiT_manual(phi_tilde, Lambda_inv)\n",
    "    Delta_lambda_n = compute_phi_lambda_phiT_manual(phi_tilde, Lambda_inv_n)\n",
    "\n",
    "    Delta_lambda_inv = np.linalg.inv(Delta_lambda)\n",
    "    \n",
    "    # Delta_lambda_inv @ Delta_lambda_n @ Delta_lambda_inv\n",
    "    result = np.matmul(np.matmul(Delta_lambda_inv, Delta_lambda_n), Delta_lambda_inv)\n",
    "    return np.linalg.cholesky(result)\n",
    "\n",
    "\n",
    "\n",
    "R = compute_R_np(eps, phi_tilde)\n",
    "print(R.shape)\n",
    "print(benchmark(compute_R_np, (eps, phi_tilde), n_repeat=100))\n",
    "functions = [\n",
    "    compute_R,\n",
    "    compute_R2\n",
    "]\n",
    "for func in functions:\n",
    "    R = func(eps, phi_tilde)\n",
    "    print(f\"{func.__name__}: \", np.allclose(R, R))\n",
    "    print(benchmark(func, (eps, phi_tilde), n_repeat=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea53e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random test data\n",
    "phi_tilde = np.random.randn(100, 500, 4, 2)\n",
    "# Lambda matrix\n",
    "eps = np.random.randn(2, 500)\n",
    "alpha = np.sign(np.random.randn(100, 2, 500))\n",
    "alpha[0, :] = 1\n",
    "N_hat_pertubed = np.multiply(alpha, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2c8d4984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 500, 4, 2) (100, 500, 2, 1)\n",
      "(100, 4, 1)\n",
      "True True True\n",
      "True True\n",
      "test_func1          :    CPU:  9051.784 us   +/- 1793.271 (min:  6071.300 / max: 13201.600) us     GPU-0:  9697.676 us   +/- 1843.813 (min:  6190.976 / max: 14249.440) us\n",
      "test_func2          :    CPU:  6138.082 us   +/- 1485.951 (min:  3798.100 / max: 15255.300) us     GPU-0:  6831.649 us   +/- 1542.071 (min:  3860.128 / max: 16242.912) us\n"
     ]
    }
   ],
   "source": [
    "@njit(cache=True, fastmath=True)\n",
    "def compute_cov_matrices_2(epsilon: np.ndarray):\n",
    "    d, N = epsilon.shape\n",
    "\n",
    "    # Step 1: Compute Lambda (covariance matrix)\n",
    "    # Lambda = 1 / (N-1) * epsilon_centered @ epsilon_centered.T\n",
    "\n",
    "    # First, compute mean of epsilon over N\n",
    "    mean_epsilon = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            mean_epsilon[i] += epsilon[i, n]\n",
    "        mean_epsilon[i] /= N\n",
    "\n",
    "    # Compute centered epsilon\n",
    "    epsilon_centered = np.zeros((d, N))\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            epsilon_centered[i, n] = epsilon[i, n] - mean_epsilon[i]\n",
    "\n",
    "    # Now compute epsilon_centered @ epsilon_centered.T\n",
    "    Lambda = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon_centered[i, n] * epsilon_centered[j, n]\n",
    "            Lambda[i, j] = sum_ / (N - 1)\n",
    "\n",
    "\n",
    "    # Step 2: Compute Lambda_n = 1/N * epsilon @ epsilon.T\n",
    "    Lambda_n = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon[i, n] * epsilon[j, n]\n",
    "            Lambda_n[i, j] = sum_ / N\n",
    "\n",
    "    # Step 3: Compute Lambda_inv\n",
    "    Lambda_inv = np.linalg.inv(Lambda)\n",
    "\n",
    "    return Lambda_inv, Lambda_n\n",
    "\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_lambda_phiT_and_phi_lambda_Y(phi_tilde, Lambda_inv, Lambda_n, N_hat_perturbed):\n",
    "    \"\"\"\n",
    "    Computes:\n",
    "      - result1 = phi @ Lambda_inv @ phi^T (averaged over T)\n",
    "      - result2 = phi @ Lambda_inv @ Lambda_n @ Lambda_inv @ phi^T (averaged over T)\n",
    "      - result3 = phi @ Lambda_inv @ N_hat_perturbed (summed over T)\n",
    "    \"\"\"\n",
    "    m, T, r, c = phi_tilde.shape\n",
    "    result1 = np.zeros((m, r, r))\n",
    "    result2 = np.zeros((m, r, r))\n",
    "    result3 = np.zeros((m, r, 1))  # result for phi_Lambda @ N_hat_perturbed\n",
    "\n",
    "    for k in prange(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # (r, c)\n",
    "\n",
    "            # Precompute phi_Lambda_inv\n",
    "            phi_Lambda_inv = np.zeros((r, c))\n",
    "            for i in range(r):\n",
    "                for l in range(c):\n",
    "                    for q in range(c):\n",
    "                        phi_Lambda_inv[i, l] += phi[i, q] * Lambda_inv[q, l]\n",
    "\n",
    "            # Compute result1 and result2\n",
    "            for i in range(r):\n",
    "                for j in range(r):\n",
    "                    sum1 = 0.0\n",
    "                    sum2 = 0.0\n",
    "                    for l in range(c):\n",
    "                        sum1 += phi_Lambda_inv[i, l] * phi[j, l]\n",
    "                        for p in range(c):\n",
    "                            sum2 += phi_Lambda_inv[i, l] * Lambda_n[l, p] * phi_Lambda_inv[j, p]\n",
    "                    result1[k, i, j] += sum1\n",
    "                    result2[k, i, j] += sum2\n",
    "\n",
    "            # Compute result3 = phi_Lambda_inv @ N_hat_perturbed\n",
    "            for i in range(r):\n",
    "                acc = 0.0\n",
    "                for l in range(c):\n",
    "                    acc += phi_Lambda_inv[i, l] * N_hat_perturbed[k, l, t]\n",
    "                result3[k, i, 0] += acc\n",
    "\n",
    "    result1 /= T\n",
    "    result2 /= T\n",
    "    result3 /= T\n",
    "\n",
    "    return result1, result2, result3\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_lambda_Y(phi_tilde, Lambda_inv, Y):\n",
    "    m, T, r, c = phi_tilde.shape  # (m, T, r, c)\n",
    "    result = np.zeros((m, r, 1))  # (m, r, 1)\n",
    "\n",
    "    for i in prange(m):       # systems\n",
    "        for j in range(T):   # time\n",
    "            for k in range(r):     # output dim (r)\n",
    "                acc = 0.0\n",
    "                for l in range(c): # inner dim (c)\n",
    "                    # Compute phi @ Lambda_inv @ Y directly\n",
    "                    for p in range(c):  # Lambda_inv interaction with Y\n",
    "                        acc += phi_tilde[i, j, k, l] * Lambda_inv[l, p] * Y[i, p, j]\n",
    "                result[i, k, 0] += acc\n",
    "    result /= T  # Average over T dimension\n",
    "    return result\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_lambda_phiT(phi_tilde, Lambda):\n",
    "    m, T, r, c = phi_tilde.shape  # (m, T, r, c)\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    for k in prange(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # (r, c)\n",
    "\n",
    "            for i in range(r):\n",
    "                for j in range(r):\n",
    "                    sum_ = 0.0\n",
    "                    for l in range(c):\n",
    "                        for p in range(c):\n",
    "                            sum_ += phi[i, l] * Lambda[l, p] * phi[j, p]\n",
    "                    result[k, i, j] += sum_\n",
    "\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def compute_cov_matrices(epsilon: np.ndarray):\n",
    "    d, N = epsilon.shape\n",
    "\n",
    "    # Step 1: Compute Lambda (covariance matrix)\n",
    "    # Lambda = 1 / (N-1) * epsilon_centered @ epsilon_centered.T\n",
    "\n",
    "    # First, compute mean of epsilon over N\n",
    "    mean_epsilon = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            mean_epsilon[i] += epsilon[i, n]\n",
    "        mean_epsilon[i] /= N\n",
    "\n",
    "    # Compute centered epsilon\n",
    "    epsilon_centered = np.zeros((d, N))\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            epsilon_centered[i, n] = epsilon[i, n] - mean_epsilon[i]\n",
    "\n",
    "    # Now compute epsilon_centered @ epsilon_centered.T\n",
    "    Lambda = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon_centered[i, n] * epsilon_centered[j, n]\n",
    "            Lambda[i, j] = sum_ / (N - 1)\n",
    "\n",
    "\n",
    "    # Step 2: Compute Lambda_n = 1/N * epsilon @ epsilon.T\n",
    "    Lambda_n = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon[i, n] * epsilon[j, n]\n",
    "            Lambda_n[i, j] = sum_ / N\n",
    "\n",
    "    # Step 3: Compute Lambda_inv\n",
    "    Lambda_inv = np.linalg.inv(Lambda)\n",
    "\n",
    "    # Step 4: Compute result = Lambda_inv @ Lambda_n @ Lambda_inv\n",
    "    # First compute temp = Lambda_inv @ Lambda_n\n",
    "    temp = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                temp[i, j] += Lambda_inv[i, k] * Lambda_n[k, j]\n",
    "\n",
    "    # Now compute result = temp @ Lambda_inv\n",
    "    result = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                result[i, j] += temp[i, k] * Lambda_inv[k, j]\n",
    "\n",
    "    return Lambda_inv, result\n",
    "\n",
    "def test_func1(eps, phi_tilde, N_hat_perturbed):\n",
    "    Lambda_inv, Lambda_inv_n = compute_cov_matrices(eps)\n",
    "    Delta_lambda = compute_phi_lambda_phiT(phi_tilde, Lambda_inv)\n",
    "    Delta_lambda_n = compute_phi_lambda_phiT(phi_tilde, Lambda_inv_n)\n",
    "    Delta_lambda_Y = compute_phi_lambda_Y(phi_tilde, Lambda_inv, N_hat_perturbed)\n",
    "    return Delta_lambda, Delta_lambda_n, Delta_lambda_Y\n",
    "\n",
    "def test_func2(eps, phi_tilde, N_hat_perturbed):\n",
    "    Lambda_inv, Lambda_n = compute_cov_matrices_2(eps)\n",
    "    Delta_lambda, Delta_lambda_n, Delta_lambda_Y = compute_phi_lambda_phiT_and_phi_lambda_Y(phi_tilde, Lambda_inv, Lambda_n, N_hat_perturbed)\n",
    "    return Delta_lambda, Delta_lambda_n, Delta_lambda_Y\n",
    "import numpy as np\n",
    "\n",
    "def compute_phi_lambda_Y_np(phi_tilde, Lambda_inv, Y):\n",
    "    # phi_tilde: (m, T, r, c)\n",
    "    # Lambda_inv: (c, c)\n",
    "    # Y: (m, c, T)\n",
    "    \n",
    "    # Step 1: Compute phi @ Lambda_inv\n",
    "    phi_lambda = np.matmul(phi_tilde, Lambda_inv)  # (m, T, r, c) @ (c, c) -> (m, T, r, c)\n",
    "    \n",
    "    # Step 2: Compute phi_lambda @ Y\n",
    "    print(phi_lambda.shape, Y.transpose(0, 2, 1)[:,:,:,None].shape)\n",
    "    result = np.matmul(phi_lambda, Y.transpose(0, 2, 1)[:,:,:,None])  # (m, T, r, c) @ (m, T, c) -> (m, T, r, 1)\n",
    "    \n",
    "    # Step 3: Average over time T\n",
    "    result = result.mean(axis=1)  # Average over T dimension\n",
    "\n",
    "    return result\n",
    "\n",
    "Lambda_inv, Lambda_n = compute_cov_matrices_2(eps)\n",
    "phi_y_np = compute_phi_lambda_Y_np(phi_tilde, Lambda_inv, N_hat_pertubed)\n",
    "print(phi_y_np.shape)\n",
    "d1, d2, y1 = test_func1(eps, phi_tilde, N_hat_pertubed)\n",
    "d3, d4, y2 = test_func2(eps, phi_tilde, N_hat_pertubed)\n",
    "print(np.allclose(d1, d3), np.allclose(d2, d4), np.allclose(y1, y2))\n",
    "print(np.allclose(y1, phi_y_np), np.allclose(y2, phi_y_np))\n",
    "print(benchmark(test_func1, (eps, phi_tilde, N_hat_pertubed), n_repeat=100))\n",
    "print(benchmark(test_func2, (eps, phi_tilde, N_hat_pertubed), n_repeat=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d93f9f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_S_np        :    CPU: 44457.008 us   +/- 8093.475 (min: 34074.700 / max: 171110.900) us     GPU-0: 44986.625 us   +/- 8115.925 (min: 35014.561 / max: 172020.538) us\n",
      "compute_S:  True\n",
      "compute_S           :    CPU:  6970.540 us   +/- 1485.662 (min:  4402.400 / max: 14675.600) us     GPU-0:  7661.185 us   +/- 1516.794 (min:  4146.528 / max: 14496.160) us\n",
      "compute_S_1:  True\n",
      "compute_S_1         :    CPU:  6866.046 us   +/- 1584.168 (min:  4303.400 / max: 21731.000) us     GPU-0:  7571.574 us   +/- 1625.275 (min:  4320.160 / max: 22451.168) us\n",
      "compute_S_2:  True\n",
      "compute_S_2         :    CPU:  6723.279 us   +/- 1434.315 (min:  4230.300 / max: 11547.800) us     GPU-0:  7442.503 us   +/- 1449.862 (min:  4351.776 / max: 12181.216) us\n",
      "compute_S_3:  True\n",
      "compute_S_3         :    CPU:  6795.107 us   +/- 1500.694 (min:  4190.500 / max: 15189.400) us     GPU-0:  7492.659 us   +/- 1537.404 (min:  4454.688 / max: 15988.352) us\n"
     ]
    }
   ],
   "source": [
    "def compute_S_np(N_hat, N_hat_perturbed, phi_tilde):\n",
    "    \"\"\"\n",
    "    Computes the R matrix using the covariance matrices and phi_tilde.\n",
    "    R = sqrt(Delat(lambda^{-1})^{-1} @ Delta(lambda^{-1}lambda_n lambda^{-1}) @ Delta(lambda^{-1})^{-1})\n",
    "    \"\"\"\n",
    "    Lambda_inv, Lambda_n = compute_cov_matrices_2(N_hat)\n",
    "    Delta_lambda, Delta_lambda_n, Delta_lambda_Y = compute_phi_lambda_phiT_and_phi_lambda_Y(phi_tilde, Lambda_inv, Lambda_n, N_hat_perturbed)\n",
    "    # Compute the R\n",
    "    m, r, _ = Delta_lambda.shape\n",
    "    S = np.zeros((m, ))\n",
    "    for i in range(m):\n",
    "        Delta_inv = np.linalg.inv(Delta_lambda[i])\n",
    "        temp = np.dot(Delta_inv, Delta_lambda_n[i])\n",
    "        R_ = np.dot(temp, Delta_inv)\n",
    "        W = np.linalg.cholesky(R_)\n",
    "        S_i = np.dot(W, Delta_lambda_Y[i])\n",
    "        S[i] = np.linalg.norm(S_i, ord=2)\n",
    "    return S\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_S(N_hat, N_hat_perturbed, phi_tilde):\n",
    "    \"\"\"\n",
    "    Compute ranking matrix S\n",
    "    Step 1: Compute covariance matrices Lambda_inv and Lambda_n\n",
    "    Step 2: Compute Delta_lambda, Delta_lambda_n, and Delta_lambda_Y using phi_tilde and covariance matrices\n",
    "    Step 3: Compute weight matrix W using Cholesky decomposition of R\n",
    "    Step 4: Compute S using the norm of the product of W and Delta_lambda_Y\n",
    "    \"\"\"\n",
    "    Lambda_inv, Lambda_n = compute_cov_matrices_2(N_hat)\n",
    "    Delta_lambda, Delta_lambda_n, Delta_lambda_Y = compute_phi_lambda_phiT_and_phi_lambda_Y(phi_tilde, Lambda_inv, Lambda_n, N_hat_perturbed)\n",
    "    # Compute the R\n",
    "    m, r, _ = Delta_lambda.shape\n",
    "    S = np.zeros((m, ))\n",
    "    for i in prange(m):\n",
    "        Delta_inv = np.linalg.inv(Delta_lambda[i])\n",
    "        temp = np.dot(Delta_inv, Delta_lambda_n[i])\n",
    "        R_ = np.dot(temp, Delta_inv)\n",
    "        W = np.linalg.cholesky(R_)\n",
    "        S_i = np.dot(W, Delta_lambda_Y[i])\n",
    "        S[i] = np.linalg.norm(S_i, ord=2)\n",
    "    return S\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_S_1(N_hat, N_hat_perturbed, phi_tilde):\n",
    "    \"\"\"\n",
    "    Compute ranking matrix S using manual loops for matrix multiplications.\n",
    "    Keep Cholesky decomposition with numpy.\n",
    "    \"\"\"\n",
    "    Lambda_inv, Lambda_n = compute_cov_matrices_2(N_hat)\n",
    "    Delta_lambda, Delta_lambda_n, Delta_lambda_Y = compute_phi_lambda_phiT_and_phi_lambda_Y(\n",
    "        phi_tilde, Lambda_inv, Lambda_n, N_hat_perturbed\n",
    "    )\n",
    "    \n",
    "    m, r, _ = Delta_lambda.shape\n",
    "    S = np.zeros((m, ))\n",
    "\n",
    "    for i in prange(m):\n",
    "        # Step 1: Invert Delta_lambda[i] (still using numpy)\n",
    "        Delta_inv = np.linalg.inv(Delta_lambda[i])\n",
    "\n",
    "        # Step 2: temp = Delta_inv @ Delta_lambda_n[i]\n",
    "        temp = np.zeros((r, r))\n",
    "        for a in range(r):\n",
    "            for b in range(r):\n",
    "                for c in range(r):\n",
    "                    temp[a, b] += Delta_inv[a, c] * Delta_lambda_n[i, c, b]\n",
    "\n",
    "        # Step 3: R_ = temp @ Delta_inv\n",
    "        R_ = np.zeros((r, r))\n",
    "        for a in range(r):\n",
    "            for b in range(r):\n",
    "                for c in range(r):\n",
    "                    R_[a, b] += temp[a, c] * Delta_inv[c, b]\n",
    "\n",
    "        # Step 4: Cholesky decomposition using numpy\n",
    "        W = np.linalg.cholesky(R_)\n",
    "\n",
    "        # Step 5: S_i = W @ Delta_lambda_Y[i]\n",
    "        S_i = np.zeros((r, 1))\n",
    "        for a in range(r):\n",
    "            for b in range(r):\n",
    "                S_i[a, 0] += W[a, b] * Delta_lambda_Y[i, b, 0]\n",
    "\n",
    "        # Step 6: Compute norm of S_i\n",
    "        norm = 0.0\n",
    "        for a in range(r):\n",
    "            norm += S_i[a, 0] ** 2\n",
    "        S[i] = np.sqrt(norm)\n",
    "\n",
    "    return S\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_S_2(N_hat, N_hat_perturbed, phi_tilde):\n",
    "    \"\"\"\n",
    "    Compute ranking matrix S using manual loops for matrix multiplications.\n",
    "    Keep Cholesky decomposition with numpy.\n",
    "    \"\"\"\n",
    "    Lambda_inv, Lambda_n = compute_cov_matrices_2(N_hat)\n",
    "    Delta_lambda, Delta_lambda_n, Delta_lambda_Y = compute_phi_lambda_phiT_and_phi_lambda_Y(\n",
    "        phi_tilde, Lambda_inv, Lambda_n, N_hat_perturbed\n",
    "    )\n",
    "    \n",
    "    m, r, _ = Delta_lambda.shape\n",
    "    S = np.zeros((m, ))\n",
    "\n",
    "    for i in prange(m):\n",
    "        Delta_inv = np.linalg.inv(Delta_lambda[i])\n",
    "\n",
    "        R_ = np.zeros((r, r))\n",
    "        for a in range(r):\n",
    "            for b in range(r):\n",
    "                for c in range(r):\n",
    "                    for d in range(r):\n",
    "                        R_[a, b] += Delta_inv[a, c] * Delta_lambda_n[i, c, d] * Delta_inv[d, b]\n",
    "\n",
    "        W = np.linalg.cholesky(R_)\n",
    "\n",
    "        S_i = np.zeros((r, 1))\n",
    "        for a in range(r):\n",
    "            for b in range(r):\n",
    "                S_i[a, 0] += W[a, b] * Delta_lambda_Y[i, b, 0]\n",
    "\n",
    "        norm = 0.0\n",
    "        for a in range(r):\n",
    "            norm += S_i[a, 0] ** 2\n",
    "        S[i] = np.sqrt(norm)\n",
    "\n",
    "\n",
    "    return S\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def compute_R(Delta_inv, Delta_lambda_n, r):\n",
    "    \"\"\"\n",
    "    Computes the R matrix using the covariance matrices and phi_tilde.\n",
    "    R = sqrt(Delat(lambda^{-1})^{-1} @ Delta(lambda^{-1}lambda_n lambda^{-1}) @ Delta(lambda^{-1})^{-1})\n",
    "    \"\"\"\n",
    "    R_ = np.zeros((r, r))\n",
    "    for a in range(r):\n",
    "        for b in range(r):\n",
    "            for c in range(r):\n",
    "                for d in range(r):\n",
    "                    R_[a, b] += Delta_inv[a, c] * Delta_lambda_n[c, d] * Delta_inv[d, b]\n",
    "\n",
    "    return R_\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_S_3(N_hat, N_hat_perturbed, phi_tilde):\n",
    "    \"\"\"\n",
    "    Compute ranking matrix S using manual loops for matrix multiplications.\n",
    "    Keep Cholesky decomposition with numpy.\n",
    "    \"\"\"\n",
    "    Lambda_inv, Lambda_n = compute_cov_matrices_2(N_hat)\n",
    "    Delta_lambda, Delta_lambda_n, Delta_lambda_Y = compute_phi_lambda_phiT_and_phi_lambda_Y(\n",
    "        phi_tilde, Lambda_inv, Lambda_n, N_hat_perturbed\n",
    "    )\n",
    "    \n",
    "    m, r, _ = Delta_lambda.shape\n",
    "    S = np.zeros((m, ))\n",
    "\n",
    "    for i in prange(m):\n",
    "        Delta_inv = np.linalg.inv(Delta_lambda[i])\n",
    "        R_ = compute_R(Delta_inv, Delta_lambda_n[i], r)\n",
    "\n",
    "        W = np.linalg.cholesky(R_)\n",
    "\n",
    "        S_i = np.zeros((r, 1))\n",
    "        for a in range(r):\n",
    "            for b in range(r):\n",
    "                S_i[a, 0] += W[a, b] * Delta_lambda_Y[i, b, 0]\n",
    "\n",
    "        norm = 0.0\n",
    "        for a in range(r):\n",
    "            norm += S_i[a, 0] ** 2\n",
    "        S[i] = np.sqrt(norm)\n",
    "\n",
    "\n",
    "    return S\n",
    "\n",
    "functions = [\n",
    "    compute_S,\n",
    "    compute_S_1,\n",
    "    compute_S_2,\n",
    "    compute_S_3,\n",
    "]\n",
    "S_np = compute_S_np(eps, N_hat_pertubed, phi_tilde)\n",
    "print(benchmark(compute_S_np, (eps, N_hat_pertubed, phi_tilde), n_repeat=1000))\n",
    "for func in functions:\n",
    "    S = func(eps, N_hat_pertubed, phi_tilde)\n",
    "    print(f\"{func.__name__}: \", np.allclose(S, S_np))\n",
    "    print(benchmark(func, (eps, N_hat_pertubed, phi_tilde), n_repeat=1000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9178734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_S           :    CPU:  7400.758 us   +/- 2151.702 (min:  4338.600 / max: 141018.900) us     GPU-0:  8072.979 us   +/- 2166.783 (min:  4219.232 / max: 141904.800) us\n",
      "compute_S_1         :    CPU:  6848.320 us   +/- 2063.395 (min:  4121.000 / max: 142062.300) us     GPU-0:  7529.344 us   +/- 2072.630 (min:  3970.816 / max: 142766.235) us\n",
      "compute_S_2         :    CPU:  7155.172 us   +/- 1841.936 (min:  4097.400 / max: 79509.800) us     GPU-0:  7826.180 us   +/- 1859.252 (min:  3787.232 / max: 80210.144) us\n",
      "compute_S_3         :    CPU:  7524.164 us   +/- 2469.835 (min:  4320.900 / max: 157025.900) us     GPU-0:  8245.184 us   +/- 2508.270 (min:  3815.424 / max: 157813.339) us\n"
     ]
    }
   ],
   "source": [
    "for func in functions:\n",
    "    S = func(eps, N_hat_pertubed, phi_tilde)\n",
    "    print(benchmark(func, (eps, N_hat_pertubed, phi_tilde), n_repeat=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc0285f",
   "metadata": {},
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_R(Lambda_inv, Lambda_inv_n , phi_tilde):\n",
    "    \"\"\"\n",
    "    Computes the R matrix using the covariance matrices and phi_tilde.\n",
    "    R = sqrt(Delat(lambda^{-1})^{-1} @ Delta(lambda^{-1}lambda_n lambda^{-1}) @ Delta(lambda^{-1})^{-1})\n",
    "    \"\"\"\n",
    "    Delta_lambda = compute_phi_lambda_phiT(phi_tilde, Lambda_inv)\n",
    "    Delta_lambda_n = compute_phi_lambda_phiT(phi_tilde, Lambda_inv_n)\n",
    "\n",
    "    m, r, _ = Delta_lambda.shape\n",
    "\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    for i in prange(m):\n",
    "        Delta_inv = np.linalg.inv(Delta_lambda[i])\n",
    "        temp = np.dot(Delta_inv, Delta_lambda_n[i])\n",
    "        R = np.dot(temp, Delta_inv)\n",
    "        result[i] = np.linalg.cholesky(R)\n",
    "\n",
    "    return result\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def compute_cov_matrices(epsilon: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    d, N = epsilon.shape\n",
    "\n",
    "    # Step 1: Compute Lambda (covariance matrix)\n",
    "    # Lambda = 1 / (N-1) * epsilon_centered @ epsilon_centered.T\n",
    "\n",
    "    # First, compute mean of epsilon over N\n",
    "    mean_epsilon = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            mean_epsilon[i] += epsilon[i, n]\n",
    "        mean_epsilon[i] /= N\n",
    "\n",
    "    # Compute centered epsilon\n",
    "    epsilon_centered = np.zeros((d, N))\n",
    "    for i in range(d):\n",
    "        for n in range(N):\n",
    "            epsilon_centered[i, n] = epsilon[i, n] - mean_epsilon[i]\n",
    "\n",
    "    # Now compute epsilon_centered @ epsilon_centered.T\n",
    "    Lambda = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon_centered[i, n] * epsilon_centered[j, n]\n",
    "            Lambda[i, j] = sum_ / (N - 1)\n",
    "\n",
    "\n",
    "    # Step 2: Compute Lambda_n = 1/N * epsilon @ epsilon.T\n",
    "    Lambda_n = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            sum_ = 0.0\n",
    "            for n in range(N):\n",
    "                sum_ += epsilon[i, n] * epsilon[j, n]\n",
    "            Lambda_n[i, j] = sum_ / N\n",
    "\n",
    "    # Step 3: Compute Lambda_inv\n",
    "    Lambda_inv = np.linalg.inv(Lambda)\n",
    "\n",
    "    # Step 4: Compute result = Lambda_inv @ Lambda_n @ Lambda_inv\n",
    "    # First compute temp = Lambda_inv @ Lambda_n\n",
    "    temp = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                temp[i, j] += Lambda_inv[i, k] * Lambda_n[k, j]\n",
    "\n",
    "    # Now compute result = temp @ Lambda_inv\n",
    "    result = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                result[i, j] += temp[i, k] * Lambda_inv[k, j]\n",
    "\n",
    "    return Lambda_inv, result\n",
    "\n",
    "@njit(cache=True, fastmath=True, parallel=True)\n",
    "def compute_phi_lambda_phiT(phi_tilde, Lambda):\n",
    "    m, T, r, c = phi_tilde.shape  # (m, T, r, c)\n",
    "    result = np.zeros((m, r, r))\n",
    "    \n",
    "    for k in prange(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # (r, c)\n",
    "\n",
    "            for i in range(r):\n",
    "                for j in range(r):\n",
    "                    sum_ = 0.0\n",
    "                    for l in range(c):\n",
    "                        for p in range(c):\n",
    "                            sum_ += phi[i, l] * Lambda[l, p] * phi[j, p]\n",
    "                    result[k, i, j] += sum_\n",
    "\n",
    "    result /= T\n",
    "    return result\n",
    "\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def compute_phi_phiT(phi_tilde):\n",
    "    m, T, r, c = phi_tilde.shape  # (3, 5, 4, 2)\n",
    "    result = np.zeros((m, r, r))\n",
    "    for k in range(m):\n",
    "        for t in range(T):\n",
    "            phi = phi_tilde[k, t]  # shape (4, 2)\n",
    "            # phi @ phi.T -> (4, 4)\n",
    "            for i in range(r):\n",
    "                for j in range(r):\n",
    "                    for l in range(c):  # inner dimension\n",
    "                        result[k, i, j] += phi[i, l] * phi[j, l]\n",
    "    result/=T\n",
    "    return result\n",
    "\n",
    "@njit(cache=True, fastmath=True)\n",
    "def compute_phi_Y(phi, Y):\n",
    "    m, t, r, c = phi.shape  # (3, 5, 4, 2)\n",
    "    result = np.zeros((m, r, 1))  # (3, 4, 1)\n",
    "\n",
    "    for i in range(m):       # systems\n",
    "        for j in range(t):   # time\n",
    "            for k in range(r):     # output dim (4)\n",
    "                acc = 0.0\n",
    "                for l in range(c): # inner dim (2)\n",
    "                    acc += phi[i, j, k, l] * Y[i, l, j]  # note: Y is (m, 2, t)\n",
    "                result[i, k, 0] += acc\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5c011",
   "metadata": {},
   "source": [
    "### armax test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10933218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "class ARMAX:\n",
    "    def __init__(self, A, B, C):\n",
    "        self.A = np.array(A)\n",
    "        self.B = np.array(B)\n",
    "        self.C = np.array(C)\n",
    "    \n",
    "    def simulate_open_loop(self, n_samples, U=None, noise_std=0.1):\n",
    "        Y = np.zeros(n_samples)\n",
    "        N = np.random.normal(0, noise_std, n_samples)\n",
    "        \n",
    "        if U is None:\n",
    "            U = np.zeros(n_samples)\n",
    "        \n",
    "        max_order = max(len(self.A), len(self.B), len(self.C))\n",
    "        \n",
    "        for t in range(max_order, n_samples):\n",
    "            Y[t] = (- np.dot(self.A[1:], Y[t-1:t-len(self.A):-1]) \n",
    "                    + np.dot(self.B, U[t-1:t-len(self.B)-1:-1])\n",
    "                    + np.dot(self.C, N[t:t-len(self.C):-1]))\n",
    "        \n",
    "        return Y, U, N\n",
    "\n",
    "    def plot_results(self, Y, U, N, R=None):\n",
    "        fig, axs = plt.subplots(4 if R is not None else 3, 1, figsize=(10, 10), sharex=True)\n",
    "        \n",
    "        axs[0].plot(Y)\n",
    "        axs[0].set_ylabel('Output (Y)')\n",
    "        axs[0].set_title('ARMAX Open-Loop Simulation Results')\n",
    "        \n",
    "        axs[1].plot(U)\n",
    "        axs[1].set_ylabel('Input (U)')\n",
    "        \n",
    "        axs[2].plot(N)\n",
    "        axs[2].set_ylabel('Noise (N)')\n",
    "        \n",
    "        if R is not None:\n",
    "            axs[3].plot(R)\n",
    "            axs[3].set_ylabel('Reference (R)')\n",
    "            axs[3].set_xlabel('Time')\n",
    "        else:\n",
    "            axs[2].set_xlabel('Time')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "A = [1, -0.33, 0.1]   # A(z^-1) = 1 - 0.33z^-1 + 0.1z^-2\n",
    "B = [0.22, 0.1]       # B(z^-1) = 0.22z^-1 + 0.1z^-2\n",
    "C = [1]               # \n",
    "\n",
    "armax_model = ARMAX(A, B, C)\n",
    "\n",
    "n_samples = 100\n",
    "U = 0.5 * signal.square(np.linspace(0, 10*np.pi, n_samples))  # External input signal\n",
    "\n",
    "Y, U, noise = armax_model.simulate_open_loop(n_samples, U, noise_std=0.07)\n",
    "armax_model.plot_results(Y, U, noise)  # No R needed for open-loop\n",
    "\n",
    "Y_dot = np.gradient(Y)\n",
    "\n",
    "U = U.reshape(1, -1)\n",
    "Y = np.vstack([Y, Y_dot])\n",
    "print(Y.shape, U.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.array([-0.33, 0.1, 0.22, 0.1])\n",
    "A_obs, B_obs, C_obs, D_obs, A,B = _construct_ss_from_params(params,C_obs)\n",
    "G = d_tfs.ss_to_tf(A_obs, B_obs, C_obs, D_obs, check_assumption=False)\n",
    "C = np.empty((n_output, 1))\n",
    "H = np.zeros((n_output, n_output), dtype=object)\n",
    "for i in range(n_output):\n",
    "    C[i]=np.array([1.0])\n",
    "    H[i,i]=d_tfs((np.array([1.0]),A))\n",
    "print(\"A_obs: \", A_obs)\n",
    "print(\"B_obs:\",  B_obs)\n",
    "print(\"C_obs: \", C_obs)\n",
    "print(\"A\",A)\n",
    "print(\"B\", B)\n",
    "print(G)\n",
    "print(H)\n",
    "print(C)\n",
    "open_loop_sps_mimo(G, H, A, B, C, Y, U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440f75b",
   "metadata": {},
   "source": [
    "## 2 input 2 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([1, 0.3, -0.2])    # a1, a2\n",
    "B = np.array([[0, 0.5, 0.1], [0, 0.8, 0.1]])     # b1, b2\n",
    "C = np.array([[1, 0.5],[1, 0.8]])          # c1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
